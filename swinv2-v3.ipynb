{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wd-swinv2-tagger-v3\n",
    "\n",
    "References:\n",
    "- Original model: https://huggingface.co/SmilingWolf/wd-swinv2-tagger-v3\n",
    "- Old training repo: https://github.com/SmilingWolf/SW-CV-ModelZoo\n",
    "- v3 repo: https://github.com/SmilingWolf/JAX-CV\n",
    "- Converting script: https://github.com/huggingface/transformers/blob/main/src/transformers/models/swinv2/convert_swinv2_timm_to_pytorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the swinv2 model\n",
    "!git clone https://huggingface.co/SmilingWolf/wd-swinv2-tagger-v3 ./swinv2-v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import AutoImageProcessor, Swinv2Config, Swinv2ForImageClassification\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Swinv2Config.from_pretrained(\"swinv2-v3-config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9999999</td>\n",
       "      <td>general</td>\n",
       "      <td>9</td>\n",
       "      <td>1589178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9999998</td>\n",
       "      <td>sensitive</td>\n",
       "      <td>9</td>\n",
       "      <td>3994361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9999997</td>\n",
       "      <td>questionable</td>\n",
       "      <td>9</td>\n",
       "      <td>892496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9999996</td>\n",
       "      <td>explicit</td>\n",
       "      <td>9</td>\n",
       "      <td>706509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>470575</td>\n",
       "      <td>1girl</td>\n",
       "      <td>0</td>\n",
       "      <td>5113288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tag_id          name  category    count\n",
       "0  9999999       general         9  1589178\n",
       "1  9999998     sensitive         9  3994361\n",
       "2  9999997  questionable         9   892496\n",
       "3  9999996      explicit         9   706509\n",
       "4   470575         1girl         0  5113288"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./swinv2-v3/selected_tags.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tag_name(tag: str, category: int):\n",
    "    if category == 0:\n",
    "        return tag\n",
    "    elif category == 4:\n",
    "        return f\"character:{tag}\"\n",
    "    elif category == 9:\n",
    "        return f\"rating:{tag}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'rating:general',\n",
       " 1: 'rating:sensitive',\n",
       " 2: 'rating:questionable',\n",
       " 3: 'rating:explicit',\n",
       " 4: '1girl',\n",
       " 5: 'solo',\n",
       " 6: 'long_hair',\n",
       " 7: 'breasts',\n",
       " 8: 'looking_at_viewer',\n",
       " 9: 'blush',\n",
       " 10: 'smile',\n",
       " 11: 'open_mouth',\n",
       " 12: 'short_hair',\n",
       " 13: 'blue_eyes',\n",
       " 14: 'simple_background',\n",
       " 15: 'shirt',\n",
       " 16: 'large_breasts',\n",
       " 17: 'skirt',\n",
       " 18: 'blonde_hair',\n",
       " 19: 'multiple_girls',\n",
       " 20: 'brown_hair',\n",
       " 21: 'black_hair',\n",
       " 22: 'long_sleeves',\n",
       " 23: 'hair_ornament',\n",
       " 24: 'white_background',\n",
       " 25: '1boy',\n",
       " 26: 'gloves',\n",
       " 27: 'red_eyes',\n",
       " 28: 'dress',\n",
       " 29: 'thighhighs',\n",
       " 30: 'hat',\n",
       " 31: 'holding',\n",
       " 32: 'bow',\n",
       " 33: 'navel',\n",
       " 34: 'animal_ears',\n",
       " 35: 'ribbon',\n",
       " 36: 'hair_between_eyes',\n",
       " 37: 'closed_mouth',\n",
       " 38: '2girls',\n",
       " 39: 'cleavage',\n",
       " 40: 'jewelry',\n",
       " 41: 'bare_shoulders',\n",
       " 42: 'very_long_hair',\n",
       " 43: 'sitting',\n",
       " 44: 'twintails',\n",
       " 45: 'medium_breasts',\n",
       " 46: 'brown_eyes',\n",
       " 47: 'standing',\n",
       " 48: 'nipples',\n",
       " 49: 'green_eyes',\n",
       " 50: 'underwear',\n",
       " 51: 'blue_hair',\n",
       " 52: 'jacket',\n",
       " 53: 'school_uniform',\n",
       " 54: 'purple_eyes',\n",
       " 55: 'collarbone',\n",
       " 56: 'tail',\n",
       " 57: 'white_shirt',\n",
       " 58: 'full_body',\n",
       " 59: 'upper_body',\n",
       " 60: 'panties',\n",
       " 61: 'closed_eyes',\n",
       " 62: 'yellow_eyes',\n",
       " 63: 'swimsuit',\n",
       " 64: 'white_hair',\n",
       " 65: 'pink_hair',\n",
       " 66: 'monochrome',\n",
       " 67: 'grey_hair',\n",
       " 68: 'ahoge',\n",
       " 69: 'braid',\n",
       " 70: 'hair_ribbon',\n",
       " 71: 'purple_hair',\n",
       " 72: 'male_focus',\n",
       " 73: 'ponytail',\n",
       " 74: 'ass',\n",
       " 75: 'flower',\n",
       " 76: 'weapon',\n",
       " 77: 'multicolored_hair',\n",
       " 78: 'short_sleeves',\n",
       " 79: 'sidelocks',\n",
       " 80: 'comic',\n",
       " 81: 'hetero',\n",
       " 82: 'heart',\n",
       " 83: 'thighs',\n",
       " 84: ':d',\n",
       " 85: 'hair_bow',\n",
       " 86: 'pantyhose',\n",
       " 87: 'outdoors',\n",
       " 88: 'cowboy_shot',\n",
       " 89: 'earrings',\n",
       " 90: 'greyscale',\n",
       " 91: 'bikini',\n",
       " 92: 'sweat',\n",
       " 93: 'red_hair',\n",
       " 94: 'nude',\n",
       " 95: 'pleated_skirt',\n",
       " 96: 'small_breasts',\n",
       " 97: 'frills',\n",
       " 98: 'hairband',\n",
       " 99: 'parted_lips',\n",
       " 100: 'censored',\n",
       " 101: 'boots',\n",
       " 102: 'open_clothes',\n",
       " 103: 'lying',\n",
       " 104: 'horns',\n",
       " 105: 'teeth',\n",
       " 106: 'multiple_boys',\n",
       " 107: 'wings',\n",
       " 108: 'food',\n",
       " 109: 'necktie',\n",
       " 110: 'one_eye_closed',\n",
       " 111: 'detached_sleeves',\n",
       " 112: 'sky',\n",
       " 113: 'penis',\n",
       " 114: 'shorts',\n",
       " 115: 'green_hair',\n",
       " 116: 'japanese_clothes',\n",
       " 117: 'shoes',\n",
       " 118: 'sleeveless',\n",
       " 119: 'black_gloves',\n",
       " 120: 'alternate_costume',\n",
       " 121: 'collared_shirt',\n",
       " 122: 'choker',\n",
       " 123: 'barefoot',\n",
       " 124: 'pussy',\n",
       " 125: 'socks',\n",
       " 126: 'glasses',\n",
       " 127: 'tongue',\n",
       " 128: 'pointy_ears',\n",
       " 129: 'solo_focus',\n",
       " 130: 'pants',\n",
       " 131: 'day',\n",
       " 132: 'virtual_youtuber',\n",
       " 133: 'serafuku',\n",
       " 134: 'indoors',\n",
       " 135: 'puffy_sleeves',\n",
       " 136: 'artist_name',\n",
       " 137: 'hairclip',\n",
       " 138: 'medium_hair',\n",
       " 139: 'belt',\n",
       " 140: 'fang',\n",
       " 141: 'black_thighhighs',\n",
       " 142: 'hand_up',\n",
       " 143: 'elbow_gloves',\n",
       " 144: 'midriff',\n",
       " 145: 'looking_back',\n",
       " 146: 'cloud',\n",
       " 147: 'white_gloves',\n",
       " 148: 'signature',\n",
       " 149: 'bowtie',\n",
       " 150: 'hood',\n",
       " 151: 'sword',\n",
       " 152: 'black_skirt',\n",
       " 153: 'dark_skin',\n",
       " 154: '2boys',\n",
       " 155: 'cat_ears',\n",
       " 156: 'blunt_bangs',\n",
       " 157: 'hair_flower',\n",
       " 158: 'official_alternate_costume',\n",
       " 159: 'tongue_out',\n",
       " 160: 'sex',\n",
       " 161: 'spread_legs',\n",
       " 162: 'pink_eyes',\n",
       " 163: 'sailor_collar',\n",
       " 164: 'wide_sleeves',\n",
       " 165: 'miniskirt',\n",
       " 166: 'stomach',\n",
       " 167: 'fingerless_gloves',\n",
       " 168: 'cum',\n",
       " 169: 'on_back',\n",
       " 170: 'tears',\n",
       " 171: 'black_footwear',\n",
       " 172: 'grey_background',\n",
       " 173: '3girls',\n",
       " 174: 'armpits',\n",
       " 175: 'twitter_username',\n",
       " 176: 'kimono',\n",
       " 177: 'white_dress',\n",
       " 178: 'holding_weapon',\n",
       " 179: 'off_shoulder',\n",
       " 180: 'necklace',\n",
       " 181: 'striped_clothes',\n",
       " 182: 'hair_bun',\n",
       " 183: 'nail_polish',\n",
       " 184: 'from_behind',\n",
       " 185: 'star_(symbol)',\n",
       " 186: 'mole',\n",
       " 187: 'looking_at_another',\n",
       " 188: 'water',\n",
       " 189: 'hair_over_one_eye',\n",
       " 190: 'bag',\n",
       " 191: 'rabbit_ears',\n",
       " 192: 'chibi',\n",
       " 193: 'orange_hair',\n",
       " 194: 'blurry',\n",
       " 195: 'grin',\n",
       " 196: 'sweatdrop',\n",
       " 197: 'clothes_lift',\n",
       " 198: 'black_dress',\n",
       " 199: 'scarf',\n",
       " 200: 'cape',\n",
       " 201: 'white_thighhighs',\n",
       " 202: 'black_eyes',\n",
       " 203: 'two-tone_hair',\n",
       " 204: 'english_text',\n",
       " 205: 'speech_bubble',\n",
       " 206: 'streaked_hair',\n",
       " 207: 'bra',\n",
       " 208: 'yuri',\n",
       " 209: 'armor',\n",
       " 210: 'huge_breasts',\n",
       " 211: 'vest',\n",
       " 212: 'open_jacket',\n",
       " 213: 'halo',\n",
       " 214: 'from_side',\n",
       " 215: 'apron',\n",
       " 216: 'mosaic_censoring',\n",
       " 217: 'feet',\n",
       " 218: 'red_bow',\n",
       " 219: 'arm_up',\n",
       " 220: 'white_panties',\n",
       " 221: 'leotard',\n",
       " 222: 'character_name',\n",
       " 223: 'coat',\n",
       " 224: 'black_jacket',\n",
       " 225: 'vaginal',\n",
       " 226: 'high_heels',\n",
       " 227: ':o',\n",
       " 228: 'collar',\n",
       " 229: 'arms_up',\n",
       " 230: 'sweater',\n",
       " 231: 'bracelet',\n",
       " 232: 'blue_sky',\n",
       " 233: 'flat_chest',\n",
       " 234: 'twin_braids',\n",
       " 235: 'dated',\n",
       " 236: 'uniform',\n",
       " 237: 'side_ponytail',\n",
       " 238: 'animal_ear_fluff',\n",
       " 239: 'red_ribbon',\n",
       " 240: 'crop_top',\n",
       " 241: 'cup',\n",
       " 242: 'aqua_eyes',\n",
       " 243: 'dark-skinned_female',\n",
       " 244: 'black_shirt',\n",
       " 245: 'covered_nipples',\n",
       " 246: 'puffy_short_sleeves',\n",
       " 247: 'parted_bangs',\n",
       " 248: 'completely_nude',\n",
       " 249: 'blue_skirt',\n",
       " 250: 'two_side_up',\n",
       " 251: 'fingernails',\n",
       " 252: 'black_pantyhose',\n",
       " 253: 'tree',\n",
       " 254: 'hands_up',\n",
       " 255: 'looking_to_the_side',\n",
       " 256: 'v-shaped_eyebrows',\n",
       " 257: 'grey_eyes',\n",
       " 258: 'orange_eyes',\n",
       " 259: 'legs',\n",
       " 260: 'neckerchief',\n",
       " 261: 'sleeves_past_wrists',\n",
       " 262: 'sketch',\n",
       " 263: 'cat_tail',\n",
       " 264: 'groin',\n",
       " 265: 'symbol-shaped_pupils',\n",
       " 266: 'eyelashes',\n",
       " 267: 'wet',\n",
       " 268: 'fur_trim',\n",
       " 269: 'see-through',\n",
       " 270: 'lips',\n",
       " 271: 'wrist_cuffs',\n",
       " 272: 'hand_on_own_hip',\n",
       " 273: 'loli',\n",
       " 274: 'pillow',\n",
       " 275: 'head_tilt',\n",
       " 276: 'gun',\n",
       " 277: 'maid',\n",
       " 278: 'strapless',\n",
       " 279: 'zettai_ryouiki',\n",
       " 280: 'clothing_cutout',\n",
       " 281: 'black_headwear',\n",
       " 282: 'plaid',\n",
       " 283: 'bar_censor',\n",
       " 284: 'torn_clothes',\n",
       " 285: 'mole_under_eye',\n",
       " 286: 'fox_ears',\n",
       " 287: 'toes',\n",
       " 288: 'multiple_views',\n",
       " 289: 'one-piece_swimsuit',\n",
       " 290: 'book',\n",
       " 291: 'sash',\n",
       " 292: 'maid_headdress',\n",
       " 293: 'sleeveless_shirt',\n",
       " 294: 'short_shorts',\n",
       " 295: 'bare_arms',\n",
       " 296: 'sleeveless_dress',\n",
       " 297: 'feet_out_of_frame',\n",
       " 298: 'pubic_hair',\n",
       " 299: 'gradient_background',\n",
       " 300: 'ascot',\n",
       " 301: 'shiny_skin',\n",
       " 302: 'v',\n",
       " 303: 'pokemon_(creature)',\n",
       " 304: 'black_panties',\n",
       " 305: 'cosplay',\n",
       " 306: 'sparkle',\n",
       " 307: 'no_humans',\n",
       " 308: 'fake_animal_ears',\n",
       " 309: 'muscular',\n",
       " 310: 'petals',\n",
       " 311: 'kneehighs',\n",
       " 312: 'bare_legs',\n",
       " 313: 'window',\n",
       " 314: 'uncensored',\n",
       " 315: 'thigh_strap',\n",
       " 316: 'black_bow',\n",
       " 317: 'single_braid',\n",
       " 318: 'covered_navel',\n",
       " 319: 'hoodie',\n",
       " 320: 'neck_ribbon',\n",
       " 321: 'black_ribbon',\n",
       " 322: 'detached_collar',\n",
       " 323: 'gradient_hair',\n",
       " 324: 'upper_teeth_only',\n",
       " 325: 'tattoo',\n",
       " 326: 'dutch_angle',\n",
       " 327: 'black_choker',\n",
       " 328: 'dress_shirt',\n",
       " 329: 'buttons',\n",
       " 330: 'double_bun',\n",
       " 331: 'blurry_background',\n",
       " 332: 'open_shirt',\n",
       " 333: 'profile',\n",
       " 334: 'sideboob',\n",
       " 335: 'kneeling',\n",
       " 336: 'makeup',\n",
       " 337: 'blood',\n",
       " 338: 'bell',\n",
       " 339: 'military',\n",
       " 340: 'hug',\n",
       " 341: 'saliva',\n",
       " 342: 'floating_hair',\n",
       " 343: 'aqua_hair',\n",
       " 344: 'mask',\n",
       " 345: 'pov',\n",
       " 346: 'colored_skin',\n",
       " 347: 'skindentation',\n",
       " 348: 'swept_bangs',\n",
       " 349: 'anus',\n",
       " 350: 'capelet',\n",
       " 351: 'bodysuit',\n",
       " 352: 'leaning_forward',\n",
       " 353: 'facial_hair',\n",
       " 354: '4girls',\n",
       " 355: 'blue_dress',\n",
       " 356: 'night',\n",
       " 357: 'shadow',\n",
       " 358: 'black_pants',\n",
       " 359: 'pussy_juice',\n",
       " 360: 'bed',\n",
       " 361: 'copyright_name',\n",
       " 362: 'no_bra',\n",
       " 363: 'black_bikini',\n",
       " 364: ':3',\n",
       " 365: '4koma',\n",
       " 366: 'heterochromia',\n",
       " 367: 'depth_of_field',\n",
       " 368: 'nose_blush',\n",
       " 369: 'white_headwear',\n",
       " 370: 'red_skirt',\n",
       " 371: 'alternate_hairstyle',\n",
       " 372: 'blue_bow',\n",
       " 373: 'turtleneck',\n",
       " 374: 'fruit',\n",
       " 375: 'fox_tail',\n",
       " 376: '^_^',\n",
       " 377: 'blue_background',\n",
       " 378: 'border',\n",
       " 379: 'underboob',\n",
       " 380: 'watermark',\n",
       " 381: 'witch_hat',\n",
       " 382: 'cum_in_pussy',\n",
       " 383: 'siblings',\n",
       " 384: 'highleg',\n",
       " 385: 'low_twintails',\n",
       " 386: 'military_uniform',\n",
       " 387: 'expressionless',\n",
       " 388: 'frown',\n",
       " 389: 'bird',\n",
       " 390: 'no_panties',\n",
       " 391: 'on_bed',\n",
       " 392: 'rose',\n",
       " 393: 'one_side_up',\n",
       " 394: 'cameltoe',\n",
       " 395: 'headband',\n",
       " 396: 'glowing',\n",
       " 397: 'black_shorts',\n",
       " 398: 'scar',\n",
       " 399: 'horse_ears',\n",
       " 400: 'bottomless',\n",
       " 401: 'beret',\n",
       " 402: 'ocean',\n",
       " 403: 'side-tie_bikini_bottom',\n",
       " 404: 'bed_sheet',\n",
       " 405: 'soles',\n",
       " 406: 'animal',\n",
       " 407: 'brown_footwear',\n",
       " 408: 'holding_hands',\n",
       " 409: 'wavy_hair',\n",
       " 410: 'fangs',\n",
       " 411: 'halterneck',\n",
       " 412: 'thick_thighs',\n",
       " 413: 'leaf',\n",
       " 414: 'chain',\n",
       " 415: 'playboy_bunny',\n",
       " 416: 'headphones',\n",
       " 417: 'piercing',\n",
       " 418: 'arm_support',\n",
       " 419: 'from_above',\n",
       " 420: 'embarrassed',\n",
       " 421: 'white_jacket',\n",
       " 422: 'holding_sword',\n",
       " 423: 'white_socks',\n",
       " 424: 'hair_intakes',\n",
       " 425: 'back',\n",
       " 426: 'blush_stickers',\n",
       " 427: 'chinese_clothes',\n",
       " 428: 'white_bikini',\n",
       " 429: 'ass_visible_through_thighs',\n",
       " 430: 'erection',\n",
       " 431: 'phone',\n",
       " 432: 'no_shoes',\n",
       " 433: 'facial_mark',\n",
       " 434: 'chair',\n",
       " 435: 'thick_eyebrows',\n",
       " 436: 'plaid_skirt',\n",
       " 437: 'abs',\n",
       " 438: 'umbrella',\n",
       " 439: 'looking_down',\n",
       " 440: 'bandages',\n",
       " 441: 'beach',\n",
       " 442: 'thigh_boots',\n",
       " 443: 'white_footwear',\n",
       " 444: 'horse_girl',\n",
       " 445: 'half-closed_eyes',\n",
       " 446: 'headgear',\n",
       " 447: 'sandals',\n",
       " 448: 'on_side',\n",
       " 449: '6+girls',\n",
       " 450: 'female_pubic_hair',\n",
       " 451: 'muscular_male',\n",
       " 452: 'floral_print',\n",
       " 453: 'heart-shaped_pupils',\n",
       " 454: 'bob_cut',\n",
       " 455: 'garter_straps',\n",
       " 456: 'short_dress',\n",
       " 457: 'drill_hair',\n",
       " 458: 'wariza',\n",
       " 459: 'arms_behind_back',\n",
       " 460: 'sunglasses',\n",
       " 461: 'obi',\n",
       " 462: 'happy',\n",
       " 463: 'pectorals',\n",
       " 464: 'red_dress',\n",
       " 465: 'testicles',\n",
       " 466: 'shirt_lift',\n",
       " 467: 'eating',\n",
       " 468: 'grabbing',\n",
       " 469: 'transparent_background',\n",
       " 470: 'traditional_media',\n",
       " 471: 'pink_background',\n",
       " 472: 'flying_sweatdrops',\n",
       " 473: 'mouth_hold',\n",
       " 474: 'stuffed_toy',\n",
       " 475: 'dark-skinned_male',\n",
       " 476: 'hood_down',\n",
       " 477: 'frilled_dress',\n",
       " 478: 'squatting',\n",
       " 479: 'clothes_pull',\n",
       " 480: 'cleavage_cutout',\n",
       " 481: 'white_skirt',\n",
       " 482: 'table',\n",
       " 483: 'blue_shirt',\n",
       " 484: 'crossed_arms',\n",
       " 485: 'parody',\n",
       " 486: 'light_brown_hair',\n",
       " 487: 'thigh_gap',\n",
       " 488: 'wavy_mouth',\n",
       " 489: 'from_below',\n",
       " 490: 'hair_tubes',\n",
       " 491: 'leg_up',\n",
       " 492: 'ring',\n",
       " 493: 'oral',\n",
       " 494: 'holding_food',\n",
       " 495: 'bound',\n",
       " 496: 'wolf_ears',\n",
       " 497: 'blue_jacket',\n",
       " 498: 'black_socks',\n",
       " 499: 'moon',\n",
       " 500: 'black_hairband',\n",
       " 501: 'white_flower',\n",
       " 502: 'eyepatch',\n",
       " 503: 'scrunchie',\n",
       " 504: 'skirt_lift',\n",
       " 505: 'sunlight',\n",
       " 506: 'standing_on_one_leg',\n",
       " 507: 'white_bow',\n",
       " 508: 'formal',\n",
       " 509: 'topless',\n",
       " 510: 'cat',\n",
       " 511: 'demon_girl',\n",
       " 512: 'cat_girl',\n",
       " 513: 'trembling',\n",
       " 514: 'mob_cap',\n",
       " 515: 'cardigan',\n",
       " 516: 'backpack',\n",
       " 517: 'magical_girl',\n",
       " 518: 'cellphone',\n",
       " 519: 'pantyshot',\n",
       " 520: 'own_hands_together',\n",
       " 521: 'eyes_visible_through_hair',\n",
       " 522: 'crossed_legs',\n",
       " 523: 'frilled_skirt',\n",
       " 524: 'grass',\n",
       " 525: 'demon_horns',\n",
       " 526: 'crying',\n",
       " 527: 'sharp_teeth',\n",
       " 528: 'tank_top',\n",
       " 529: 'sleeping',\n",
       " 530: 'cover',\n",
       " 531: 'single_hair_bun',\n",
       " 532: 'cloudy_sky',\n",
       " 533: 'blazer',\n",
       " 534: 'suspenders',\n",
       " 535: 'high_ponytail',\n",
       " 536: 'helmet',\n",
       " 537: 'suit',\n",
       " 538: 'feathers',\n",
       " 539: '3boys',\n",
       " 540: 'cum_on_body',\n",
       " 541: 'bottle',\n",
       " 542: 'stuffed_animal',\n",
       " 543: 'x_hair_ornament',\n",
       " 544: 'underwear_only',\n",
       " 545: 'bdsm',\n",
       " 546: 'fox_girl',\n",
       " 547: 'plant',\n",
       " 548: 'black_background',\n",
       " 549: 'blue_ribbon',\n",
       " 550: 'frilled_sleeves',\n",
       " 551: \"grabbing_another's_breast\",\n",
       " 552: 'portrait',\n",
       " 553: 'antenna_hair',\n",
       " 554: 'looking_up',\n",
       " 555: 'light_smile',\n",
       " 556: 'bara',\n",
       " 557: 'school_swimsuit',\n",
       " 558: 'straddling',\n",
       " 559: 'cross',\n",
       " 560: 'hat_ribbon',\n",
       " 561: 'fire',\n",
       " 562: 'bug',\n",
       " 563: 'denim',\n",
       " 564: 'crown',\n",
       " 565: 'knee_boots',\n",
       " 566: 'pink_bow',\n",
       " 567: ';d',\n",
       " 568: 'red_necktie',\n",
       " 569: 'lifted_by_self',\n",
       " 570: 'outstretched_arms',\n",
       " 571: 'fellatio',\n",
       " 572: 'tiara',\n",
       " 573: 'katana',\n",
       " 574: 'couple',\n",
       " 575: 'breasts_out',\n",
       " 576: 'aged_down',\n",
       " 577: 'red_flower',\n",
       " 578: 'on_stomach',\n",
       " 579: 'crossover',\n",
       " 580: 'juliet_sleeves',\n",
       " 581: 'robot',\n",
       " 582: 'curtains',\n",
       " 583: 'motion_lines',\n",
       " 584: 'spiked_hair',\n",
       " 585: 'sisters',\n",
       " 586: 'sex_from_behind',\n",
       " 587: 'girl_on_top',\n",
       " 588: 'polka_dot',\n",
       " 589: '>_<',\n",
       " 590: 'black_nails',\n",
       " 591: 'knife',\n",
       " 592: 'bat_wings',\n",
       " 593: 'ear_piercing',\n",
       " 594: 'outstretched_arm',\n",
       " 595: '?',\n",
       " 596: 'slit_pupils',\n",
       " 597: 'wing_collar',\n",
       " 598: 'bent_over',\n",
       " 599: 'pointing',\n",
       " 600: 'lingerie',\n",
       " 601: 'animal_print',\n",
       " 602: 'clenched_teeth',\n",
       " 603: 'bright_pupils',\n",
       " 604: 'red_shirt',\n",
       " 605: 'elf',\n",
       " 606: '5girls',\n",
       " 607: 'undressing',\n",
       " 608: 'striped_thighhighs',\n",
       " 609: 'blue_sailor_collar',\n",
       " 610: 'monster_girl',\n",
       " 611: 'rabbit_tail',\n",
       " 612: 'sneakers',\n",
       " 613: 'black_leotard',\n",
       " 614: 'hand_on_own_chest',\n",
       " 615: 'white_border',\n",
       " 616: 't-shirt',\n",
       " 617: 'tassel',\n",
       " 618: 'holding_gun',\n",
       " 619: 'head_wings',\n",
       " 620: 'all_fours',\n",
       " 621: 'gem',\n",
       " 622: 'yaoi',\n",
       " 623: 'red_footwear',\n",
       " 624: 'white_apron',\n",
       " 625: 'tan',\n",
       " 626: 'bondage',\n",
       " 627: 'red_bowtie',\n",
       " 628: 'furry',\n",
       " 629: 'hair_bobbles',\n",
       " 630: 'short_twintails',\n",
       " 631: 'messy_hair',\n",
       " 632: 'lipstick',\n",
       " 633: 'green_skirt',\n",
       " 634: 'goggles',\n",
       " 635: 'shoulder_armor',\n",
       " 636: 'holding_cup',\n",
       " 637: 'brooch',\n",
       " 638: 'building',\n",
       " 639: 'group_sex',\n",
       " 640: 'polearm',\n",
       " 641: 'black_bra',\n",
       " 642: 'horse_tail',\n",
       " 643: 'otoko_no_ko',\n",
       " 644: 'fishnets',\n",
       " 645: 'staff',\n",
       " 646: 'shaded_face',\n",
       " 647: '1other',\n",
       " 648: 'letterboxed',\n",
       " 649: 'loafers',\n",
       " 650: 'crescent',\n",
       " 651: 'towel',\n",
       " 652: 'straight_hair',\n",
       " 653: 'star_(sky)',\n",
       " 654: 'cherry_blossoms',\n",
       " 655: 'single_thighhigh',\n",
       " 656: 'kiss',\n",
       " 657: 'feathered_wings',\n",
       " 658: 'clenched_hand',\n",
       " 659: 'bandaid',\n",
       " 660: 'pink_dress',\n",
       " 661: '^^^',\n",
       " 662: 'strapless_leotard',\n",
       " 663: 'box',\n",
       " 664: 'hat_bow',\n",
       " 665: 'wind',\n",
       " 666: 'facing_viewer',\n",
       " 667: 'grey_shirt',\n",
       " 668: 'black_necktie',\n",
       " 669: 'multiple_tails',\n",
       " 670: 'drooling',\n",
       " 671: 'no_pants',\n",
       " 672: 'extra_ears',\n",
       " 673: 'eyewear_on_head',\n",
       " 674: 'demon_tail',\n",
       " 675: 'steam',\n",
       " 676: 'bike_shorts',\n",
       " 677: 'yellow_background',\n",
       " 678: 'dog_ears',\n",
       " 679: 'hooded_jacket',\n",
       " 680: 'armband',\n",
       " 681: 'instrument',\n",
       " 682: 'casual',\n",
       " 683: 'butterfly',\n",
       " 684: 'surprised',\n",
       " 685: 'night_sky',\n",
       " 686: 'panty_pull',\n",
       " 687: 'foreshortening',\n",
       " 688: 'sex_toy',\n",
       " 689: 'pale_skin',\n",
       " 690: 'child',\n",
       " 691: 'breast_press',\n",
       " 692: 'revealing_clothes',\n",
       " 693: 'anal',\n",
       " 694: 'red_headwear',\n",
       " 695: 'gauntlets',\n",
       " 696: 'white_ribbon',\n",
       " 697: 'rope',\n",
       " 698: 'sheath',\n",
       " 699: 'china_dress',\n",
       " 700: 'ribbon_trim',\n",
       " 701: 'pink_panties',\n",
       " 702: 'adapted_costume',\n",
       " 703: 'knees_up',\n",
       " 704: 'multicolored_clothes',\n",
       " 705: 'cover_page',\n",
       " 706: 'candy',\n",
       " 707: 'wristband',\n",
       " 708: 'between_breasts',\n",
       " 709: 'red_background',\n",
       " 710: 'couch',\n",
       " 711: 'hakama',\n",
       " 712: 'blouse',\n",
       " 713: 'wet_clothes',\n",
       " 714: 'musical_note',\n",
       " 715: 'colored_inner_hair',\n",
       " 716: 'hair_over_shoulder',\n",
       " 717: 'ejaculation',\n",
       " 718: 'scenery',\n",
       " 719: 'skin_fang',\n",
       " 720: 'puffy_long_sleeves',\n",
       " 721: 'arms_behind_head',\n",
       " 722: 'veil',\n",
       " 723: 'nature',\n",
       " 724: 'breath',\n",
       " 725: 'male_pubic_hair',\n",
       " 726: 'red_jacket',\n",
       " 727: 'genderswap',\n",
       " 728: 'mole_under_mouth',\n",
       " 729: 'red_nails',\n",
       " 730: 'lace_trim',\n",
       " 731: 'covering_privates',\n",
       " 732: 'side_braid',\n",
       " 733: 'third_eye',\n",
       " 734: 'scar_on_face',\n",
       " 735: 'waist_apron',\n",
       " 736: 'smartphone',\n",
       " 737: 'microphone',\n",
       " 738: 'facial',\n",
       " 739: 'skirt_set',\n",
       " 740: 'christmas',\n",
       " 741: 'web_address',\n",
       " 742: 'large_pectorals',\n",
       " 743: 'pink_flower',\n",
       " 744: 'pelvic_curtain',\n",
       " 745: 'light_blush',\n",
       " 746: '...',\n",
       " 747: 'strapless_dress',\n",
       " 748: 'anger_vein',\n",
       " 749: 'baseball_cap',\n",
       " 750: 'beard',\n",
       " 751: 'string_bikini',\n",
       " 752: 'interlocked_fingers',\n",
       " 753: 'striped_panties',\n",
       " 754: 'light_particles',\n",
       " 755: 'blue_headwear',\n",
       " 756: 'claws',\n",
       " 757: 'breasts_apart',\n",
       " 758: 'bridal_gauntlets',\n",
       " 759: 'cloak',\n",
       " 760: 'toenails',\n",
       " 761: 'peaked_cap',\n",
       " 762: 'index_finger_raised',\n",
       " 763: 'highleg_leotard',\n",
       " 764: 'red_neckerchief',\n",
       " 765: 'glowing_eyes',\n",
       " 766: 'white_pupils',\n",
       " 767: 'short_hair_with_long_locks',\n",
       " 768: 'purple_dress',\n",
       " 769: 'side-tie_panties',\n",
       " 770: 'semi-rimless_eyewear',\n",
       " 771: 'low_ponytail',\n",
       " 772: 'white_pantyhose',\n",
       " 773: 'convenient_censoring',\n",
       " 774: 'jingle_bell',\n",
       " 775: 'motor_vehicle',\n",
       " 776: 'hand_fan',\n",
       " 777: 'two-tone_background',\n",
       " 778: 'grey_skirt',\n",
       " 779: 'front-tie_top',\n",
       " 780: 'bow_panties',\n",
       " 781: 'mecha',\n",
       " 782: 'buckle',\n",
       " 783: 'hair_flaps',\n",
       " 784: 'twin_drills',\n",
       " 785: 'clothes_writing',\n",
       " 786: 'areola_slip',\n",
       " 787: 'carrying',\n",
       " 788: 'pom_pom_(clothes)',\n",
       " 789: 'clothing_aside',\n",
       " 790: 'androgynous',\n",
       " 791: 'pink_nails',\n",
       " 792: 'micro_bikini',\n",
       " 793: 'angry',\n",
       " 794: 'close-up',\n",
       " 795: 'yellow_bow',\n",
       " 796: 'maid_apron',\n",
       " 797: 'forehead',\n",
       " 798: 'sleeves_past_fingers',\n",
       " 799: 'hood_up',\n",
       " 800: 'wolf_tail',\n",
       " 801: 'meme',\n",
       " 802: 'cum_on_breasts',\n",
       " 803: 'corset',\n",
       " 804: 'neck_bell',\n",
       " 805: 'blue_nails',\n",
       " 806: 'skin_tight',\n",
       " 807: 'hand_on_own_face',\n",
       " 808: 'paizuri',\n",
       " 809: 'rifle',\n",
       " 810: 'o-ring',\n",
       " 811: 'eyeshadow',\n",
       " 812: 'tentacles',\n",
       " 813: 'patreon_username',\n",
       " 814: 'hakama_skirt',\n",
       " 815: 'black_belt',\n",
       " 816: 'lace',\n",
       " 817: 'holding_phone',\n",
       " 818: 'french_braid',\n",
       " 819: 'no_headwear',\n",
       " 820: 'tokin_hat',\n",
       " 821: 'spoken_heart',\n",
       " 822: ':<',\n",
       " 823: 'white_sleeves',\n",
       " 824: 'cropped_jacket',\n",
       " 825: 'eye_contact',\n",
       " 826: 'curvy',\n",
       " 827: 'cropped_legs',\n",
       " 828: 'faceless',\n",
       " 829: 'licking',\n",
       " 830: 'bikini_top_only',\n",
       " 831: 'brown_gloves',\n",
       " 832: 'crossed_bangs',\n",
       " 833: 'plate',\n",
       " 834: 'restrained',\n",
       " 835: 'snow',\n",
       " 836: 'outside_border',\n",
       " 837: 'red_gloves',\n",
       " 838: 'mary_janes',\n",
       " 839: 'full_moon',\n",
       " 840: 'spikes',\n",
       " 841: 'tearing_up',\n",
       " 842: 'colored_sclera',\n",
       " 843: 'black_wings',\n",
       " 844: 'science_fiction',\n",
       " 845: 'blue_bikini',\n",
       " 846: 'holding_book',\n",
       " 847: ':p',\n",
       " 848: 'side_slit',\n",
       " 849: 'gift',\n",
       " 850: 'desk',\n",
       " 851: 'black_coat',\n",
       " 852: 'camisole',\n",
       " 853: 'alternate_breast_size',\n",
       " 854: 'finger_to_mouth',\n",
       " 855: 'ball',\n",
       " 856: 'strap_slip',\n",
       " 857: 'armlet',\n",
       " 858: 'green_bow',\n",
       " 859: 'single_horn',\n",
       " 860: 'lens_flare',\n",
       " 861: 'cowgirl_position',\n",
       " 862: 'floating',\n",
       " 863: 'dragon_horns',\n",
       " 864: 'drinking_glass',\n",
       " 865: 'hair_scrunchie',\n",
       " 866: 'arm_at_side',\n",
       " 867: 'sleeves_rolled_up',\n",
       " 868: 'seiza',\n",
       " 869: 'genderswap_(mtf)',\n",
       " 870: 'gold_trim',\n",
       " 871: 'puffy_nipples',\n",
       " 872: 'blue_necktie',\n",
       " 873: 'santa_hat',\n",
       " 874: 'clenched_hands',\n",
       " 875: 'after_sex',\n",
       " 876: 'black_sailor_collar',\n",
       " 877: 'wide_hips',\n",
       " 878: 'pink_skirt',\n",
       " 879: 'single_glove',\n",
       " 880: 'pink_ribbon',\n",
       " 881: 'veins',\n",
       " 882: 'smoke',\n",
       " 883: 'tareme',\n",
       " 884: 'white_sailor_collar',\n",
       " 885: 'handgun',\n",
       " 886: 'heavy_breathing',\n",
       " 887: 'between_legs',\n",
       " 888: 'half_updo',\n",
       " 889: 'zipper',\n",
       " 890: 'knee_up',\n",
       " 891: 'brown_background',\n",
       " 892: 'starry_sky',\n",
       " 893: 'masturbation',\n",
       " 894: 'blue_flower',\n",
       " 895: 'handjob',\n",
       " 896: 'tsurime',\n",
       " 897: 'open_coat',\n",
       " 898: 'freckles',\n",
       " 899: 'blue_shorts',\n",
       " 900: 'demon_wings',\n",
       " 901: 'wading',\n",
       " 902: 'pencil_skirt',\n",
       " 903: 'happy_birthday',\n",
       " 904: 'fish',\n",
       " 905: 'green_background',\n",
       " 906: 'pink_shirt',\n",
       " 907: 'alcohol',\n",
       " 908: 'clothed_sex',\n",
       " 909: 'pendant',\n",
       " 910: 'ribbed_sweater',\n",
       " 911: 'topless_male',\n",
       " 912: 'dual_persona',\n",
       " 913: 'clothed_female_nude_male',\n",
       " 914: 'high_heel_boots',\n",
       " 915: 'track_jacket',\n",
       " 916: 'single_earring',\n",
       " 917: 'outline',\n",
       " 918: 'frilled_apron',\n",
       " 919: 'spot_color',\n",
       " 920: 'partially_submerged',\n",
       " 921: 'tray',\n",
       " 922: 'low-tied_long_hair',\n",
       " 923: 'asymmetrical_legwear',\n",
       " 924: 'swim_ring',\n",
       " 925: 'sweater_vest',\n",
       " 926: 'purple_background',\n",
       " 927: 'cross-laced_footwear',\n",
       " 928: 'arm_behind_back',\n",
       " 929: 'reflection',\n",
       " 930: 'forest',\n",
       " 931: '!',\n",
       " 932: 'upskirt',\n",
       " 933: 'legs_up',\n",
       " 934: 'headset',\n",
       " 935: 'black_vest',\n",
       " 936: 'frilled_bikini',\n",
       " 937: 'walking',\n",
       " 938: 'cake',\n",
       " 939: 'white_skin',\n",
       " 940: 'hair_rings',\n",
       " 941: 'beads',\n",
       " 942: 'pocket',\n",
       " 943: 'personification',\n",
       " 944: 'one-hour_drawing_challenge',\n",
       " 945: 'mature_male',\n",
       " 946: 'backlighting',\n",
       " 947: 'halloween',\n",
       " 948: 'vertical-striped_clothes',\n",
       " 949: 'bulge',\n",
       " 950: 'dress_lift',\n",
       " 951: 'green_dress',\n",
       " 952: 'unworn_headwear',\n",
       " 953: 'frilled_shirt_collar',\n",
       " 954: 'legs_apart',\n",
       " 955: 'long_fingernails',\n",
       " 956: 'toned',\n",
       " 957: 'mole_on_breast',\n",
       " 958: 'broom',\n",
       " 959: 'black-framed_eyewear',\n",
       " 960: 'arm_behind_head',\n",
       " 961: 'brown_pantyhose',\n",
       " 962: 'thong',\n",
       " 963: 'condom',\n",
       " 964: 'red_bikini',\n",
       " 965: 'short_ponytail',\n",
       " 966: 'out_of_frame',\n",
       " 967: 'purple_bow',\n",
       " 968: 'long_skirt',\n",
       " 969: 'high-waist_skirt',\n",
       " 970: 'round_eyewear',\n",
       " 971: 'crying_with_eyes_open',\n",
       " 972: 'rain',\n",
       " 973: 'blue_footwear',\n",
       " 974: 'crossdressing',\n",
       " 975: 'angel_wings',\n",
       " 976: 'white_bra',\n",
       " 977: 'cuffs',\n",
       " 978: 'flying',\n",
       " 979: 'gym_uniform',\n",
       " 980: 'cumdrip',\n",
       " 981: 'purple_skirt',\n",
       " 982: 'yellow_shirt',\n",
       " 983: 'cropped_torso',\n",
       " 984: 'one_eye_covered',\n",
       " 985: 'goggles_on_head',\n",
       " 986: 'bubble',\n",
       " 987: 'black_bowtie',\n",
       " 988: 'hand_in_own_hair',\n",
       " 989: 'braided_ponytail',\n",
       " 990: 'age_difference',\n",
       " 991: 'red-framed_eyewear',\n",
       " 992: 'fingering',\n",
       " 993: 'epaulettes',\n",
       " 994: 'curly_hair',\n",
       " 995: 'empty_eyes',\n",
       " 996: 'ribbon-trimmed_sleeves',\n",
       " 997: 'dot_nose',\n",
       " 998: 'santa_costume',\n",
       " 999: 'futanari',\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {\n",
    "    i: convert_tag_name(tag, df[\"category\"][i]) for i, tag in enumerate(df[\"name\"])\n",
    "}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.id2label = id2label\n",
    "config.label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.save_pretrained(\"swinv2-v3-hf\")  # save the config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load models and convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_key(name):\n",
    "    if \"patch_embed.proj\" in name:\n",
    "        name = name.replace(\n",
    "            \"patch_embed.proj\", \"embeddings.patch_embeddings.projection\"\n",
    "        )\n",
    "    if \"patch_embed.norm\" in name:\n",
    "        name = name.replace(\"patch_embed.norm\", \"embeddings.norm\")\n",
    "    if \"layers\" in name:\n",
    "        name = \"encoder.\" + name\n",
    "    if \"attn.proj\" in name:\n",
    "        name = name.replace(\"attn.proj\", \"attention.output.dense\")\n",
    "    if \"attn\" in name:\n",
    "        name = name.replace(\"attn\", \"attention.self\")\n",
    "    if \"norm1\" in name:\n",
    "        name = name.replace(\"norm1\", \"layernorm_before\")\n",
    "    if \"norm2\" in name:\n",
    "        name = name.replace(\"norm2\", \"layernorm_after\")\n",
    "    if \"mlp.fc1\" in name:\n",
    "        name = name.replace(\"mlp.fc1\", \"intermediate.dense\")\n",
    "    if \"mlp.fc2\" in name:\n",
    "        name = name.replace(\"mlp.fc2\", \"output.dense\")\n",
    "    if \"q_bias\" in name:\n",
    "        name = name.replace(\"q_bias\", \"query.bias\")\n",
    "    if \"k_bias\" in name:\n",
    "        name = name.replace(\"k_bias\", \"key.bias\")\n",
    "    if \"v_bias\" in name:\n",
    "        name = name.replace(\"v_bias\", \"value.bias\")\n",
    "    if \"cpb_mlp\" in name:\n",
    "        name = name.replace(\"cpb_mlp\", \"continuous_position_bias_mlp\")\n",
    "    if name == \"norm.weight\":\n",
    "        name = \"layernorm.weight\"\n",
    "    if name == \"norm.bias\":\n",
    "        name = \"layernorm.bias\"\n",
    "\n",
    "    if \"head.fc\" in name:\n",
    "        name = name.replace(\"head.fc\", \"classifier\")\n",
    "    else:\n",
    "        name = \"swinv2.\" + name\n",
    "\n",
    "    if \"1.downsample\" in name:\n",
    "        name = name.replace(\"1.downsample\", \"0.downsample\")\n",
    "    elif \"2.downsample\" in name:\n",
    "        name = name.replace(\"2.downsample\", \"1.downsample\")\n",
    "    elif \"3.downsample\" in name:\n",
    "        name = name.replace(\"3.downsample\", \"2.downsample\")\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state_dict(orig_state_dict, model):\n",
    "    for key in orig_state_dict.copy().keys():\n",
    "        val = orig_state_dict.pop(key)\n",
    "\n",
    "        if \"mask\" in key:\n",
    "            continue\n",
    "        elif \"qkv\" in key:\n",
    "            key_split = key.split(\".\")\n",
    "            layer_num = int(key_split[1])\n",
    "            block_num = int(key_split[3])\n",
    "            dim = (\n",
    "                model.swinv2.encoder.layers[layer_num]\n",
    "                .blocks[block_num]\n",
    "                .attention.self.all_head_size\n",
    "            )\n",
    "\n",
    "            if \"weight\" in key:\n",
    "                orig_state_dict[\n",
    "                    f\"swinv2.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.query.weight\"\n",
    "                ] = val[:dim, :]\n",
    "                orig_state_dict[\n",
    "                    f\"swinv2.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.key.weight\"\n",
    "                ] = val[dim : dim * 2, :]\n",
    "                orig_state_dict[\n",
    "                    f\"swinv2.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.value.weight\"\n",
    "                ] = val[-dim:, :]\n",
    "            else:\n",
    "                orig_state_dict[\n",
    "                    f\"swinv2.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.query.bias\"\n",
    "                ] = val[:dim]\n",
    "                orig_state_dict[\n",
    "                    f\"swinv2.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.key.bias\"\n",
    "                ] = val[dim : dim * 2]\n",
    "                orig_state_dict[\n",
    "                    f\"swinv2.encoder.layers.{layer_num}.blocks.{block_num}.attention.self.value.bias\"\n",
    "                ] = val[-dim:]\n",
    "        else:\n",
    "            orig_state_dict[rename_key(key)] = val\n",
    "\n",
    "    return orig_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm_file = load_file(\"./swinv2-v3/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['head.fc.bias',\n",
       " 'head.fc.weight',\n",
       " 'layers.0.blocks.0.attn.cpb_mlp.0.bias',\n",
       " 'layers.0.blocks.0.attn.cpb_mlp.0.weight',\n",
       " 'layers.0.blocks.0.attn.cpb_mlp.2.weight',\n",
       " 'layers.0.blocks.0.attn.logit_scale',\n",
       " 'layers.0.blocks.0.attn.proj.bias',\n",
       " 'layers.0.blocks.0.attn.proj.weight',\n",
       " 'layers.0.blocks.0.attn.q_bias',\n",
       " 'layers.0.blocks.0.attn.qkv.weight',\n",
       " 'layers.0.blocks.0.attn.v_bias',\n",
       " 'layers.0.blocks.0.mlp.fc1.bias',\n",
       " 'layers.0.blocks.0.mlp.fc1.weight',\n",
       " 'layers.0.blocks.0.mlp.fc2.bias',\n",
       " 'layers.0.blocks.0.mlp.fc2.weight',\n",
       " 'layers.0.blocks.0.norm1.bias',\n",
       " 'layers.0.blocks.0.norm1.weight',\n",
       " 'layers.0.blocks.0.norm2.bias',\n",
       " 'layers.0.blocks.0.norm2.weight',\n",
       " 'layers.0.blocks.1.attn.cpb_mlp.0.bias',\n",
       " 'layers.0.blocks.1.attn.cpb_mlp.0.weight',\n",
       " 'layers.0.blocks.1.attn.cpb_mlp.2.weight',\n",
       " 'layers.0.blocks.1.attn.logit_scale',\n",
       " 'layers.0.blocks.1.attn.proj.bias',\n",
       " 'layers.0.blocks.1.attn.proj.weight',\n",
       " 'layers.0.blocks.1.attn.q_bias',\n",
       " 'layers.0.blocks.1.attn.qkv.weight',\n",
       " 'layers.0.blocks.1.attn.v_bias',\n",
       " 'layers.0.blocks.1.mlp.fc1.bias',\n",
       " 'layers.0.blocks.1.mlp.fc1.weight',\n",
       " 'layers.0.blocks.1.mlp.fc2.bias',\n",
       " 'layers.0.blocks.1.mlp.fc2.weight',\n",
       " 'layers.0.blocks.1.norm1.bias',\n",
       " 'layers.0.blocks.1.norm1.weight',\n",
       " 'layers.0.blocks.1.norm2.bias',\n",
       " 'layers.0.blocks.1.norm2.weight',\n",
       " 'layers.1.blocks.0.attn.cpb_mlp.0.bias',\n",
       " 'layers.1.blocks.0.attn.cpb_mlp.0.weight',\n",
       " 'layers.1.blocks.0.attn.cpb_mlp.2.weight',\n",
       " 'layers.1.blocks.0.attn.logit_scale',\n",
       " 'layers.1.blocks.0.attn.proj.bias',\n",
       " 'layers.1.blocks.0.attn.proj.weight',\n",
       " 'layers.1.blocks.0.attn.q_bias',\n",
       " 'layers.1.blocks.0.attn.qkv.weight',\n",
       " 'layers.1.blocks.0.attn.v_bias',\n",
       " 'layers.1.blocks.0.mlp.fc1.bias',\n",
       " 'layers.1.blocks.0.mlp.fc1.weight',\n",
       " 'layers.1.blocks.0.mlp.fc2.bias',\n",
       " 'layers.1.blocks.0.mlp.fc2.weight',\n",
       " 'layers.1.blocks.0.norm1.bias',\n",
       " 'layers.1.blocks.0.norm1.weight',\n",
       " 'layers.1.blocks.0.norm2.bias',\n",
       " 'layers.1.blocks.0.norm2.weight',\n",
       " 'layers.1.blocks.1.attn.cpb_mlp.0.bias',\n",
       " 'layers.1.blocks.1.attn.cpb_mlp.0.weight',\n",
       " 'layers.1.blocks.1.attn.cpb_mlp.2.weight',\n",
       " 'layers.1.blocks.1.attn.logit_scale',\n",
       " 'layers.1.blocks.1.attn.proj.bias',\n",
       " 'layers.1.blocks.1.attn.proj.weight',\n",
       " 'layers.1.blocks.1.attn.q_bias',\n",
       " 'layers.1.blocks.1.attn.qkv.weight',\n",
       " 'layers.1.blocks.1.attn.v_bias',\n",
       " 'layers.1.blocks.1.mlp.fc1.bias',\n",
       " 'layers.1.blocks.1.mlp.fc1.weight',\n",
       " 'layers.1.blocks.1.mlp.fc2.bias',\n",
       " 'layers.1.blocks.1.mlp.fc2.weight',\n",
       " 'layers.1.blocks.1.norm1.bias',\n",
       " 'layers.1.blocks.1.norm1.weight',\n",
       " 'layers.1.blocks.1.norm2.bias',\n",
       " 'layers.1.blocks.1.norm2.weight',\n",
       " 'layers.1.downsample.norm.bias',\n",
       " 'layers.1.downsample.norm.weight',\n",
       " 'layers.1.downsample.reduction.weight',\n",
       " 'layers.2.blocks.0.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.0.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.0.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.0.attn.logit_scale',\n",
       " 'layers.2.blocks.0.attn.proj.bias',\n",
       " 'layers.2.blocks.0.attn.proj.weight',\n",
       " 'layers.2.blocks.0.attn.q_bias',\n",
       " 'layers.2.blocks.0.attn.qkv.weight',\n",
       " 'layers.2.blocks.0.attn.v_bias',\n",
       " 'layers.2.blocks.0.mlp.fc1.bias',\n",
       " 'layers.2.blocks.0.mlp.fc1.weight',\n",
       " 'layers.2.blocks.0.mlp.fc2.bias',\n",
       " 'layers.2.blocks.0.mlp.fc2.weight',\n",
       " 'layers.2.blocks.0.norm1.bias',\n",
       " 'layers.2.blocks.0.norm1.weight',\n",
       " 'layers.2.blocks.0.norm2.bias',\n",
       " 'layers.2.blocks.0.norm2.weight',\n",
       " 'layers.2.blocks.1.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.1.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.1.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.1.attn.logit_scale',\n",
       " 'layers.2.blocks.1.attn.proj.bias',\n",
       " 'layers.2.blocks.1.attn.proj.weight',\n",
       " 'layers.2.blocks.1.attn.q_bias',\n",
       " 'layers.2.blocks.1.attn.qkv.weight',\n",
       " 'layers.2.blocks.1.attn.v_bias',\n",
       " 'layers.2.blocks.1.mlp.fc1.bias',\n",
       " 'layers.2.blocks.1.mlp.fc1.weight',\n",
       " 'layers.2.blocks.1.mlp.fc2.bias',\n",
       " 'layers.2.blocks.1.mlp.fc2.weight',\n",
       " 'layers.2.blocks.1.norm1.bias',\n",
       " 'layers.2.blocks.1.norm1.weight',\n",
       " 'layers.2.blocks.1.norm2.bias',\n",
       " 'layers.2.blocks.1.norm2.weight',\n",
       " 'layers.2.blocks.10.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.10.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.10.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.10.attn.logit_scale',\n",
       " 'layers.2.blocks.10.attn.proj.bias',\n",
       " 'layers.2.blocks.10.attn.proj.weight',\n",
       " 'layers.2.blocks.10.attn.q_bias',\n",
       " 'layers.2.blocks.10.attn.qkv.weight',\n",
       " 'layers.2.blocks.10.attn.v_bias',\n",
       " 'layers.2.blocks.10.mlp.fc1.bias',\n",
       " 'layers.2.blocks.10.mlp.fc1.weight',\n",
       " 'layers.2.blocks.10.mlp.fc2.bias',\n",
       " 'layers.2.blocks.10.mlp.fc2.weight',\n",
       " 'layers.2.blocks.10.norm1.bias',\n",
       " 'layers.2.blocks.10.norm1.weight',\n",
       " 'layers.2.blocks.10.norm2.bias',\n",
       " 'layers.2.blocks.10.norm2.weight',\n",
       " 'layers.2.blocks.11.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.11.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.11.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.11.attn.logit_scale',\n",
       " 'layers.2.blocks.11.attn.proj.bias',\n",
       " 'layers.2.blocks.11.attn.proj.weight',\n",
       " 'layers.2.blocks.11.attn.q_bias',\n",
       " 'layers.2.blocks.11.attn.qkv.weight',\n",
       " 'layers.2.blocks.11.attn.v_bias',\n",
       " 'layers.2.blocks.11.mlp.fc1.bias',\n",
       " 'layers.2.blocks.11.mlp.fc1.weight',\n",
       " 'layers.2.blocks.11.mlp.fc2.bias',\n",
       " 'layers.2.blocks.11.mlp.fc2.weight',\n",
       " 'layers.2.blocks.11.norm1.bias',\n",
       " 'layers.2.blocks.11.norm1.weight',\n",
       " 'layers.2.blocks.11.norm2.bias',\n",
       " 'layers.2.blocks.11.norm2.weight',\n",
       " 'layers.2.blocks.12.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.12.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.12.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.12.attn.logit_scale',\n",
       " 'layers.2.blocks.12.attn.proj.bias',\n",
       " 'layers.2.blocks.12.attn.proj.weight',\n",
       " 'layers.2.blocks.12.attn.q_bias',\n",
       " 'layers.2.blocks.12.attn.qkv.weight',\n",
       " 'layers.2.blocks.12.attn.v_bias',\n",
       " 'layers.2.blocks.12.mlp.fc1.bias',\n",
       " 'layers.2.blocks.12.mlp.fc1.weight',\n",
       " 'layers.2.blocks.12.mlp.fc2.bias',\n",
       " 'layers.2.blocks.12.mlp.fc2.weight',\n",
       " 'layers.2.blocks.12.norm1.bias',\n",
       " 'layers.2.blocks.12.norm1.weight',\n",
       " 'layers.2.blocks.12.norm2.bias',\n",
       " 'layers.2.blocks.12.norm2.weight',\n",
       " 'layers.2.blocks.13.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.13.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.13.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.13.attn.logit_scale',\n",
       " 'layers.2.blocks.13.attn.proj.bias',\n",
       " 'layers.2.blocks.13.attn.proj.weight',\n",
       " 'layers.2.blocks.13.attn.q_bias',\n",
       " 'layers.2.blocks.13.attn.qkv.weight',\n",
       " 'layers.2.blocks.13.attn.v_bias',\n",
       " 'layers.2.blocks.13.mlp.fc1.bias',\n",
       " 'layers.2.blocks.13.mlp.fc1.weight',\n",
       " 'layers.2.blocks.13.mlp.fc2.bias',\n",
       " 'layers.2.blocks.13.mlp.fc2.weight',\n",
       " 'layers.2.blocks.13.norm1.bias',\n",
       " 'layers.2.blocks.13.norm1.weight',\n",
       " 'layers.2.blocks.13.norm2.bias',\n",
       " 'layers.2.blocks.13.norm2.weight',\n",
       " 'layers.2.blocks.14.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.14.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.14.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.14.attn.logit_scale',\n",
       " 'layers.2.blocks.14.attn.proj.bias',\n",
       " 'layers.2.blocks.14.attn.proj.weight',\n",
       " 'layers.2.blocks.14.attn.q_bias',\n",
       " 'layers.2.blocks.14.attn.qkv.weight',\n",
       " 'layers.2.blocks.14.attn.v_bias',\n",
       " 'layers.2.blocks.14.mlp.fc1.bias',\n",
       " 'layers.2.blocks.14.mlp.fc1.weight',\n",
       " 'layers.2.blocks.14.mlp.fc2.bias',\n",
       " 'layers.2.blocks.14.mlp.fc2.weight',\n",
       " 'layers.2.blocks.14.norm1.bias',\n",
       " 'layers.2.blocks.14.norm1.weight',\n",
       " 'layers.2.blocks.14.norm2.bias',\n",
       " 'layers.2.blocks.14.norm2.weight',\n",
       " 'layers.2.blocks.15.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.15.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.15.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.15.attn.logit_scale',\n",
       " 'layers.2.blocks.15.attn.proj.bias',\n",
       " 'layers.2.blocks.15.attn.proj.weight',\n",
       " 'layers.2.blocks.15.attn.q_bias',\n",
       " 'layers.2.blocks.15.attn.qkv.weight',\n",
       " 'layers.2.blocks.15.attn.v_bias',\n",
       " 'layers.2.blocks.15.mlp.fc1.bias',\n",
       " 'layers.2.blocks.15.mlp.fc1.weight',\n",
       " 'layers.2.blocks.15.mlp.fc2.bias',\n",
       " 'layers.2.blocks.15.mlp.fc2.weight',\n",
       " 'layers.2.blocks.15.norm1.bias',\n",
       " 'layers.2.blocks.15.norm1.weight',\n",
       " 'layers.2.blocks.15.norm2.bias',\n",
       " 'layers.2.blocks.15.norm2.weight',\n",
       " 'layers.2.blocks.16.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.16.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.16.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.16.attn.logit_scale',\n",
       " 'layers.2.blocks.16.attn.proj.bias',\n",
       " 'layers.2.blocks.16.attn.proj.weight',\n",
       " 'layers.2.blocks.16.attn.q_bias',\n",
       " 'layers.2.blocks.16.attn.qkv.weight',\n",
       " 'layers.2.blocks.16.attn.v_bias',\n",
       " 'layers.2.blocks.16.mlp.fc1.bias',\n",
       " 'layers.2.blocks.16.mlp.fc1.weight',\n",
       " 'layers.2.blocks.16.mlp.fc2.bias',\n",
       " 'layers.2.blocks.16.mlp.fc2.weight',\n",
       " 'layers.2.blocks.16.norm1.bias',\n",
       " 'layers.2.blocks.16.norm1.weight',\n",
       " 'layers.2.blocks.16.norm2.bias',\n",
       " 'layers.2.blocks.16.norm2.weight',\n",
       " 'layers.2.blocks.17.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.17.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.17.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.17.attn.logit_scale',\n",
       " 'layers.2.blocks.17.attn.proj.bias',\n",
       " 'layers.2.blocks.17.attn.proj.weight',\n",
       " 'layers.2.blocks.17.attn.q_bias',\n",
       " 'layers.2.blocks.17.attn.qkv.weight',\n",
       " 'layers.2.blocks.17.attn.v_bias',\n",
       " 'layers.2.blocks.17.mlp.fc1.bias',\n",
       " 'layers.2.blocks.17.mlp.fc1.weight',\n",
       " 'layers.2.blocks.17.mlp.fc2.bias',\n",
       " 'layers.2.blocks.17.mlp.fc2.weight',\n",
       " 'layers.2.blocks.17.norm1.bias',\n",
       " 'layers.2.blocks.17.norm1.weight',\n",
       " 'layers.2.blocks.17.norm2.bias',\n",
       " 'layers.2.blocks.17.norm2.weight',\n",
       " 'layers.2.blocks.2.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.2.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.2.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.2.attn.logit_scale',\n",
       " 'layers.2.blocks.2.attn.proj.bias',\n",
       " 'layers.2.blocks.2.attn.proj.weight',\n",
       " 'layers.2.blocks.2.attn.q_bias',\n",
       " 'layers.2.blocks.2.attn.qkv.weight',\n",
       " 'layers.2.blocks.2.attn.v_bias',\n",
       " 'layers.2.blocks.2.mlp.fc1.bias',\n",
       " 'layers.2.blocks.2.mlp.fc1.weight',\n",
       " 'layers.2.blocks.2.mlp.fc2.bias',\n",
       " 'layers.2.blocks.2.mlp.fc2.weight',\n",
       " 'layers.2.blocks.2.norm1.bias',\n",
       " 'layers.2.blocks.2.norm1.weight',\n",
       " 'layers.2.blocks.2.norm2.bias',\n",
       " 'layers.2.blocks.2.norm2.weight',\n",
       " 'layers.2.blocks.3.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.3.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.3.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.3.attn.logit_scale',\n",
       " 'layers.2.blocks.3.attn.proj.bias',\n",
       " 'layers.2.blocks.3.attn.proj.weight',\n",
       " 'layers.2.blocks.3.attn.q_bias',\n",
       " 'layers.2.blocks.3.attn.qkv.weight',\n",
       " 'layers.2.blocks.3.attn.v_bias',\n",
       " 'layers.2.blocks.3.mlp.fc1.bias',\n",
       " 'layers.2.blocks.3.mlp.fc1.weight',\n",
       " 'layers.2.blocks.3.mlp.fc2.bias',\n",
       " 'layers.2.blocks.3.mlp.fc2.weight',\n",
       " 'layers.2.blocks.3.norm1.bias',\n",
       " 'layers.2.blocks.3.norm1.weight',\n",
       " 'layers.2.blocks.3.norm2.bias',\n",
       " 'layers.2.blocks.3.norm2.weight',\n",
       " 'layers.2.blocks.4.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.4.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.4.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.4.attn.logit_scale',\n",
       " 'layers.2.blocks.4.attn.proj.bias',\n",
       " 'layers.2.blocks.4.attn.proj.weight',\n",
       " 'layers.2.blocks.4.attn.q_bias',\n",
       " 'layers.2.blocks.4.attn.qkv.weight',\n",
       " 'layers.2.blocks.4.attn.v_bias',\n",
       " 'layers.2.blocks.4.mlp.fc1.bias',\n",
       " 'layers.2.blocks.4.mlp.fc1.weight',\n",
       " 'layers.2.blocks.4.mlp.fc2.bias',\n",
       " 'layers.2.blocks.4.mlp.fc2.weight',\n",
       " 'layers.2.blocks.4.norm1.bias',\n",
       " 'layers.2.blocks.4.norm1.weight',\n",
       " 'layers.2.blocks.4.norm2.bias',\n",
       " 'layers.2.blocks.4.norm2.weight',\n",
       " 'layers.2.blocks.5.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.5.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.5.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.5.attn.logit_scale',\n",
       " 'layers.2.blocks.5.attn.proj.bias',\n",
       " 'layers.2.blocks.5.attn.proj.weight',\n",
       " 'layers.2.blocks.5.attn.q_bias',\n",
       " 'layers.2.blocks.5.attn.qkv.weight',\n",
       " 'layers.2.blocks.5.attn.v_bias',\n",
       " 'layers.2.blocks.5.mlp.fc1.bias',\n",
       " 'layers.2.blocks.5.mlp.fc1.weight',\n",
       " 'layers.2.blocks.5.mlp.fc2.bias',\n",
       " 'layers.2.blocks.5.mlp.fc2.weight',\n",
       " 'layers.2.blocks.5.norm1.bias',\n",
       " 'layers.2.blocks.5.norm1.weight',\n",
       " 'layers.2.blocks.5.norm2.bias',\n",
       " 'layers.2.blocks.5.norm2.weight',\n",
       " 'layers.2.blocks.6.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.6.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.6.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.6.attn.logit_scale',\n",
       " 'layers.2.blocks.6.attn.proj.bias',\n",
       " 'layers.2.blocks.6.attn.proj.weight',\n",
       " 'layers.2.blocks.6.attn.q_bias',\n",
       " 'layers.2.blocks.6.attn.qkv.weight',\n",
       " 'layers.2.blocks.6.attn.v_bias',\n",
       " 'layers.2.blocks.6.mlp.fc1.bias',\n",
       " 'layers.2.blocks.6.mlp.fc1.weight',\n",
       " 'layers.2.blocks.6.mlp.fc2.bias',\n",
       " 'layers.2.blocks.6.mlp.fc2.weight',\n",
       " 'layers.2.blocks.6.norm1.bias',\n",
       " 'layers.2.blocks.6.norm1.weight',\n",
       " 'layers.2.blocks.6.norm2.bias',\n",
       " 'layers.2.blocks.6.norm2.weight',\n",
       " 'layers.2.blocks.7.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.7.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.7.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.7.attn.logit_scale',\n",
       " 'layers.2.blocks.7.attn.proj.bias',\n",
       " 'layers.2.blocks.7.attn.proj.weight',\n",
       " 'layers.2.blocks.7.attn.q_bias',\n",
       " 'layers.2.blocks.7.attn.qkv.weight',\n",
       " 'layers.2.blocks.7.attn.v_bias',\n",
       " 'layers.2.blocks.7.mlp.fc1.bias',\n",
       " 'layers.2.blocks.7.mlp.fc1.weight',\n",
       " 'layers.2.blocks.7.mlp.fc2.bias',\n",
       " 'layers.2.blocks.7.mlp.fc2.weight',\n",
       " 'layers.2.blocks.7.norm1.bias',\n",
       " 'layers.2.blocks.7.norm1.weight',\n",
       " 'layers.2.blocks.7.norm2.bias',\n",
       " 'layers.2.blocks.7.norm2.weight',\n",
       " 'layers.2.blocks.8.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.8.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.8.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.8.attn.logit_scale',\n",
       " 'layers.2.blocks.8.attn.proj.bias',\n",
       " 'layers.2.blocks.8.attn.proj.weight',\n",
       " 'layers.2.blocks.8.attn.q_bias',\n",
       " 'layers.2.blocks.8.attn.qkv.weight',\n",
       " 'layers.2.blocks.8.attn.v_bias',\n",
       " 'layers.2.blocks.8.mlp.fc1.bias',\n",
       " 'layers.2.blocks.8.mlp.fc1.weight',\n",
       " 'layers.2.blocks.8.mlp.fc2.bias',\n",
       " 'layers.2.blocks.8.mlp.fc2.weight',\n",
       " 'layers.2.blocks.8.norm1.bias',\n",
       " 'layers.2.blocks.8.norm1.weight',\n",
       " 'layers.2.blocks.8.norm2.bias',\n",
       " 'layers.2.blocks.8.norm2.weight',\n",
       " 'layers.2.blocks.9.attn.cpb_mlp.0.bias',\n",
       " 'layers.2.blocks.9.attn.cpb_mlp.0.weight',\n",
       " 'layers.2.blocks.9.attn.cpb_mlp.2.weight',\n",
       " 'layers.2.blocks.9.attn.logit_scale',\n",
       " 'layers.2.blocks.9.attn.proj.bias',\n",
       " 'layers.2.blocks.9.attn.proj.weight',\n",
       " 'layers.2.blocks.9.attn.q_bias',\n",
       " 'layers.2.blocks.9.attn.qkv.weight',\n",
       " 'layers.2.blocks.9.attn.v_bias',\n",
       " 'layers.2.blocks.9.mlp.fc1.bias',\n",
       " 'layers.2.blocks.9.mlp.fc1.weight',\n",
       " 'layers.2.blocks.9.mlp.fc2.bias',\n",
       " 'layers.2.blocks.9.mlp.fc2.weight',\n",
       " 'layers.2.blocks.9.norm1.bias',\n",
       " 'layers.2.blocks.9.norm1.weight',\n",
       " 'layers.2.blocks.9.norm2.bias',\n",
       " 'layers.2.blocks.9.norm2.weight',\n",
       " 'layers.2.downsample.norm.bias',\n",
       " 'layers.2.downsample.norm.weight',\n",
       " 'layers.2.downsample.reduction.weight',\n",
       " 'layers.3.blocks.0.attn.cpb_mlp.0.bias',\n",
       " 'layers.3.blocks.0.attn.cpb_mlp.0.weight',\n",
       " 'layers.3.blocks.0.attn.cpb_mlp.2.weight',\n",
       " 'layers.3.blocks.0.attn.logit_scale',\n",
       " 'layers.3.blocks.0.attn.proj.bias',\n",
       " 'layers.3.blocks.0.attn.proj.weight',\n",
       " 'layers.3.blocks.0.attn.q_bias',\n",
       " 'layers.3.blocks.0.attn.qkv.weight',\n",
       " 'layers.3.blocks.0.attn.v_bias',\n",
       " 'layers.3.blocks.0.mlp.fc1.bias',\n",
       " 'layers.3.blocks.0.mlp.fc1.weight',\n",
       " 'layers.3.blocks.0.mlp.fc2.bias',\n",
       " 'layers.3.blocks.0.mlp.fc2.weight',\n",
       " 'layers.3.blocks.0.norm1.bias',\n",
       " 'layers.3.blocks.0.norm1.weight',\n",
       " 'layers.3.blocks.0.norm2.bias',\n",
       " 'layers.3.blocks.0.norm2.weight',\n",
       " 'layers.3.blocks.1.attn.cpb_mlp.0.bias',\n",
       " 'layers.3.blocks.1.attn.cpb_mlp.0.weight',\n",
       " 'layers.3.blocks.1.attn.cpb_mlp.2.weight',\n",
       " 'layers.3.blocks.1.attn.logit_scale',\n",
       " 'layers.3.blocks.1.attn.proj.bias',\n",
       " 'layers.3.blocks.1.attn.proj.weight',\n",
       " 'layers.3.blocks.1.attn.q_bias',\n",
       " 'layers.3.blocks.1.attn.qkv.weight',\n",
       " 'layers.3.blocks.1.attn.v_bias',\n",
       " 'layers.3.blocks.1.mlp.fc1.bias',\n",
       " 'layers.3.blocks.1.mlp.fc1.weight',\n",
       " 'layers.3.blocks.1.mlp.fc2.bias',\n",
       " 'layers.3.blocks.1.mlp.fc2.weight',\n",
       " 'layers.3.blocks.1.norm1.bias',\n",
       " 'layers.3.blocks.1.norm1.weight',\n",
       " 'layers.3.blocks.1.norm2.bias',\n",
       " 'layers.3.blocks.1.norm2.weight',\n",
       " 'layers.3.downsample.norm.bias',\n",
       " 'layers.3.downsample.norm.weight',\n",
       " 'layers.3.downsample.reduction.weight',\n",
       " 'norm.bias',\n",
       " 'norm.weight',\n",
       " 'patch_embed.norm.bias',\n",
       " 'patch_embed.norm.weight',\n",
       " 'patch_embed.proj.bias',\n",
       " 'patch_embed.proj.weight']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(timm_file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Swinv2ForImageClassification(\n",
       "  (swinv2): Swinv2Model(\n",
       "    (embeddings): Swinv2Embeddings(\n",
       "      (patch_embeddings): Swinv2PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Swinv2Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (key): Linear(in_features=128, out_features=128, bias=False)\n",
       "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (key): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (intermediate_act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-17): 18 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=False)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (intermediate_act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=10861, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Swinv2ForImageClassification(config)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swinv2.embeddings.patch_embeddings.projection.weight',\n",
       " 'swinv2.embeddings.patch_embeddings.projection.bias',\n",
       " 'swinv2.embeddings.norm.weight',\n",
       " 'swinv2.embeddings.norm.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.0.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.0.blocks.0.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.0.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.0.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.0.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.0.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.0.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.0.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.0.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.0.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.0.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.0.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.0.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.0.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.0.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.0.output.dense.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.0.output.dense.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.0.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.0.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.1.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.0.blocks.1.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.1.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.1.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.1.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.1.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.1.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.1.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.1.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.1.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.1.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.1.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.1.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.1.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.1.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.1.output.dense.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.1.output.dense.bias',\n",
       " 'swinv2.encoder.layers.0.blocks.1.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.0.blocks.1.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.0.downsample.reduction.weight',\n",
       " 'swinv2.encoder.layers.0.downsample.norm.weight',\n",
       " 'swinv2.encoder.layers.0.downsample.norm.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.0.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.1.blocks.0.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.0.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.0.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.0.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.0.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.0.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.0.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.0.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.0.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.0.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.0.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.0.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.0.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.0.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.0.output.dense.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.0.output.dense.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.0.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.0.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.1.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.1.blocks.1.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.1.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.1.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.1.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.1.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.1.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.1.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.1.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.1.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.1.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.1.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.1.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.1.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.1.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.1.output.dense.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.1.output.dense.bias',\n",
       " 'swinv2.encoder.layers.1.blocks.1.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.1.blocks.1.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.1.downsample.reduction.weight',\n",
       " 'swinv2.encoder.layers.1.downsample.norm.weight',\n",
       " 'swinv2.encoder.layers.1.downsample.norm.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.0.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.0.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.0.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.0.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.0.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.0.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.0.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.0.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.0.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.0.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.0.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.0.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.0.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.0.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.0.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.0.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.0.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.0.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.0.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.1.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.1.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.1.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.1.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.1.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.1.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.1.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.1.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.1.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.1.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.1.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.1.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.1.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.1.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.1.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.1.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.1.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.1.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.1.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.2.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.2.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.2.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.2.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.2.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.2.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.2.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.2.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.2.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.2.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.2.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.2.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.2.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.2.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.2.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.2.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.2.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.2.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.2.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.3.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.3.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.3.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.3.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.3.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.3.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.3.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.3.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.3.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.3.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.3.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.3.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.3.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.3.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.3.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.3.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.3.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.3.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.3.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.4.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.4.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.4.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.4.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.4.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.4.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.4.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.4.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.4.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.4.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.4.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.4.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.4.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.4.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.4.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.4.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.4.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.5.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.5.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.5.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.5.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.5.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.5.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.5.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.5.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.5.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.5.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.5.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.5.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.5.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.5.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.5.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.5.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.5.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.6.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.6.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.6.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.6.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.6.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.6.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.6.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.6.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.6.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.6.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.6.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.6.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.6.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.6.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.6.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.6.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.6.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.6.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.6.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.7.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.7.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.7.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.7.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.7.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.7.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.7.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.7.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.7.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.7.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.7.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.7.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.7.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.7.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.7.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.7.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.7.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.7.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.7.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.8.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.8.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.8.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.8.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.8.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.8.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.8.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.8.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.8.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.8.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.8.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.8.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.8.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.8.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.8.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.8.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.8.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.8.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.8.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.9.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.9.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.9.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.9.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.9.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.9.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.9.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.9.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.9.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.9.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.9.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.9.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.9.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.9.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.9.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.9.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.9.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.9.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.9.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.10.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.10.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.10.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.10.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.10.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.10.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.10.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.10.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.10.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.10.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.10.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.10.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.10.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.10.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.10.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.10.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.10.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.10.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.10.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.11.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.11.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.11.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.11.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.11.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.11.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.11.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.11.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.11.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.11.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.11.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.11.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.11.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.11.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.11.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.11.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.11.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.11.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.11.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.12.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.12.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.12.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.12.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.12.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.12.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.12.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.12.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.12.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.12.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.12.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.12.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.12.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.12.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.12.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.12.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.12.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.12.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.12.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.13.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.13.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.13.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.13.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.13.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.13.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.13.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.13.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.13.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.13.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.13.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.13.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.13.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.13.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.13.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.13.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.13.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.13.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.13.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.14.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.14.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.14.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.14.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.14.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.14.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.14.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.14.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.14.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.14.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.14.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.14.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.14.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.14.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.14.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.14.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.14.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.14.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.14.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.15.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.15.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.15.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.15.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.15.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.15.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.15.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.15.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.15.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.15.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.15.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.15.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.15.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.15.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.15.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.15.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.15.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.15.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.15.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.16.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.16.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.16.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.16.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.16.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.16.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.16.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.16.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.16.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.16.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.16.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.16.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.16.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.16.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.16.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.16.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.16.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.16.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.16.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.17.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.2.blocks.17.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.17.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.17.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.17.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.17.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.17.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.17.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.17.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.17.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.17.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.17.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.17.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.17.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.17.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.17.output.dense.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.17.output.dense.bias',\n",
       " 'swinv2.encoder.layers.2.blocks.17.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.2.blocks.17.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.2.downsample.reduction.weight',\n",
       " 'swinv2.encoder.layers.2.downsample.norm.weight',\n",
       " 'swinv2.encoder.layers.2.downsample.norm.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.0.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.3.blocks.0.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.0.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.0.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.0.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.0.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.0.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.0.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.0.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.0.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.0.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.0.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.0.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.0.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.0.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.0.output.dense.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.0.output.dense.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.0.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.0.layernorm_after.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.1.attention.self.logit_scale',\n",
       " 'swinv2.encoder.layers.3.blocks.1.attention.self.continuous_position_bias_mlp.0.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.1.attention.self.continuous_position_bias_mlp.0.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.1.attention.self.continuous_position_bias_mlp.2.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.1.attention.self.query.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.1.attention.self.query.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.1.attention.self.key.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.1.attention.self.value.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.1.attention.self.value.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.1.attention.output.dense.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.1.attention.output.dense.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.1.layernorm_before.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.1.layernorm_before.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.1.intermediate.dense.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.1.intermediate.dense.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.1.output.dense.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.1.output.dense.bias',\n",
       " 'swinv2.encoder.layers.3.blocks.1.layernorm_after.weight',\n",
       " 'swinv2.encoder.layers.3.blocks.1.layernorm_after.bias',\n",
       " 'swinv2.layernorm.weight',\n",
       " 'swinv2.layernorm.bias',\n",
       " 'classifier.weight',\n",
       " 'classifier.bias']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state_dict = convert_state_dict(timm_file, model)\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.0890e-01, 8.8995e-02, 9.5065e-04,  ..., 1.8553e-06, 5.5421e-07,\n",
       "        1.3558e-06])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\n",
    "    \"swinv2-v3-config\", trust_remote_code=True\n",
    ")\n",
    "image = Image.open(\"./sample.jpg\")\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = torch.sigmoid(outputs.logits[0])\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1girl': tensor(0.9963),\n",
       " 'solo': tensor(0.9634),\n",
       " 'school_uniform': tensor(0.9550),\n",
       " 'short_hair': tensor(0.9407),\n",
       " 'skirt': tensor(0.9385),\n",
       " 'outdoors': tensor(0.9270),\n",
       " 'serafuku': tensor(0.9171),\n",
       " 'rating:general': tensor(0.9089),\n",
       " 'sky': tensor(0.8537),\n",
       " 'cloud': tensor(0.8494),\n",
       " 'sailor_collar': tensor(0.7718),\n",
       " 'bottle': tensor(0.7138),\n",
       " 'pleated_skirt': tensor(0.7047),\n",
       " 'black_skirt': tensor(0.6987),\n",
       " 'long_sleeves': tensor(0.6412),\n",
       " 'shirt': tensor(0.6234),\n",
       " 'neckerchief': tensor(0.6087),\n",
       " 'black_hair': tensor(0.5551),\n",
       " 'water': tensor(0.5268),\n",
       " 'railing': tensor(0.5240),\n",
       " 'sunset': tensor(0.5207),\n",
       " 'scenery': tensor(0.5109),\n",
       " 'standing': tensor(0.5085),\n",
       " 'black_sailor_collar': tensor(0.5049),\n",
       " 'black_serafuku': tensor(0.4917),\n",
       " 'ocean': tensor(0.4829),\n",
       " 'cowboy_shot': tensor(0.4727),\n",
       " 'cloudy_sky': tensor(0.4689),\n",
       " 'profile': tensor(0.4669),\n",
       " 'closed_mouth': tensor(0.3929),\n",
       " 'from_behind': tensor(0.3805),\n",
       " 'lighthouse': tensor(0.3789),\n",
       " 'brown_hair': tensor(0.3671),\n",
       " 'black_shirt': tensor(0.3579),\n",
       " 'brown_skirt': tensor(0.3523),\n",
       " 'mountainous_horizon': tensor(0.3501),\n",
       " 'horizon': tensor(0.3102),\n",
       " 'water_bottle': tensor(0.2743),\n",
       " 'bob_cut': tensor(0.2182),\n",
       " 'evening': tensor(0.2000),\n",
       " 'orange_sky': tensor(0.1900),\n",
       " 'mountain': tensor(0.1815),\n",
       " 'blue_sky': tensor(0.1758),\n",
       " 'building': tensor(0.1754),\n",
       " 'wind': tensor(0.1590),\n",
       " 'brown_shirt': tensor(0.1534),\n",
       " 'looking_afar': tensor(0.1475),\n",
       " 'bridge': tensor(0.1382),\n",
       " 'looking_back': tensor(0.1299),\n",
       " 'utility_pole': tensor(0.1242),\n",
       " 'looking_to_the_side': tensor(0.1231),\n",
       " 'expressionless': tensor(0.1145),\n",
       " 'tower': tensor(0.1138),\n",
       " 'floating_hair': tensor(0.1124),\n",
       " 'day': tensor(0.1086),\n",
       " 'from_side': tensor(0.1062),\n",
       " 'blue_neckerchief': tensor(0.0988),\n",
       " 'fence': tensor(0.0942),\n",
       " 'hill': tensor(0.0935),\n",
       " 'lake': tensor(0.0922),\n",
       " 'twilight': tensor(0.0898),\n",
       " 'black_eyes': tensor(0.0895),\n",
       " 'rating:sensitive': tensor(0.0890),\n",
       " 'looking_ahead': tensor(0.0880),\n",
       " 'river': tensor(0.0876),\n",
       " 'boat': tensor(0.0863),\n",
       " 'watercraft': tensor(0.0832),\n",
       " 'miniskirt': tensor(0.0765),\n",
       " 'closed_eyes': tensor(0.0755),\n",
       " 'brown_serafuku': tensor(0.0727),\n",
       " 'reflection': tensor(0.0695),\n",
       " 'purple_neckerchief': tensor(0.0692),\n",
       " 'red_neckerchief': tensor(0.0666),\n",
       " 'brown_eyes': tensor(0.0626),\n",
       " 'against_railing': tensor(0.0603),\n",
       " 'yellow_sky': tensor(0.0575),\n",
       " 'brown_sailor_collar': tensor(0.0554),\n",
       " 'town': tensor(0.0540),\n",
       " 'dusk': tensor(0.0464),\n",
       " 'power_lines': tensor(0.0461),\n",
       " 'waves': tensor(0.0449),\n",
       " 'cityscape': tensor(0.0441),\n",
       " 'guard_rail': tensor(0.0419),\n",
       " 'uniform': tensor(0.0387),\n",
       " 'pier': tensor(0.0380),\n",
       " 'landscape': tensor(0.0371),\n",
       " 'smile': tensor(0.0363),\n",
       " 'beach': tensor(0.0360),\n",
       " 'parted_lips': tensor(0.0352),\n",
       " 'gradient_sky': tensor(0.0327),\n",
       " 'shore': tensor(0.0310),\n",
       " 'city': tensor(0.0302),\n",
       " 'signature': tensor(0.0296),\n",
       " 'crane_(machine)': tensor(0.0274),\n",
       " 'hair_between_eyes': tensor(0.0270),\n",
       " 'medium_hair': tensor(0.0265),\n",
       " 'arm_support': tensor(0.0247),\n",
       " 'sleeve_cuffs': tensor(0.0238),\n",
       " 'feet_out_of_frame': tensor(0.0236),\n",
       " 'looking_at_viewer': tensor(0.0228),\n",
       " 'film_grain': tensor(0.0227),\n",
       " 'reflective_water': tensor(0.0226),\n",
       " 'house': tensor(0.0226),\n",
       " 'holding': tensor(0.0216),\n",
       " 'turning_head': tensor(0.0202),\n",
       " 'balcony': tensor(0.0192),\n",
       " 'blouse': tensor(0.0192),\n",
       " 'traditional_media': tensor(0.0186),\n",
       " 'sunlight': tensor(0.0181),\n",
       " 'shadow': tensor(0.0179),\n",
       " 'holding_bottle': tensor(0.0177),\n",
       " 'walking': tensor(0.0175),\n",
       " 'wide_shot': tensor(0.0173),\n",
       " 'red_skirt': tensor(0.0172),\n",
       " 'sailor_shirt': tensor(0.0170),\n",
       " 'bag': tensor(0.0169),\n",
       " 'orange_theme': tensor(0.0165),\n",
       " 'legs_together': tensor(0.0163),\n",
       " 'tree': tensor(0.0163),\n",
       " 'facing_away': tensor(0.0161),\n",
       " 'dock': tensor(0.0159),\n",
       " 'blue_eyes': tensor(0.0157),\n",
       " 'skyline': tensor(0.0155),\n",
       " 'ramune': tensor(0.0155),\n",
       " 'artist_name': tensor(0.0149),\n",
       " 'sidelocks': tensor(0.0147),\n",
       " 'road': tensor(0.0147),\n",
       " 'sun': tensor(0.0139),\n",
       " 'rooftop': tensor(0.0138),\n",
       " 'breasts': tensor(0.0136),\n",
       " 'island': tensor(0.0131),\n",
       " 'black_neckerchief': tensor(0.0129),\n",
       " 'wind_lift': tensor(0.0129),\n",
       " 'cumulonimbus_cloud': tensor(0.0128),\n",
       " 'white_sailor_collar': tensor(0.0126),\n",
       " 'sailor_collar_lift': tensor(0.0126),\n",
       " 'grey_sky': tensor(0.0124),\n",
       " 'blush': tensor(0.0124),\n",
       " 'clock': tensor(0.0119),\n",
       " 'lamppost': tensor(0.0118),\n",
       " 'white_shirt': tensor(0.0118),\n",
       " 'sunrise': tensor(0.0115),\n",
       " 'medium_skirt': tensor(0.0112),\n",
       " 'arms_at_sides': tensor(0.0112),\n",
       " 'backlighting': tensor(0.0112),\n",
       " 'blurry': tensor(0.0111),\n",
       " 'wading': tensor(0.0108),\n",
       " 'puffy_long_sleeves': tensor(0.0106),\n",
       " 'thighs': tensor(0.0105),\n",
       " 'necktie': tensor(0.0103),\n",
       " 'ship': tensor(0.0103),\n",
       " 'red_sky': tensor(0.0101),\n",
       " 'glass_bottle': tensor(0.0098),\n",
       " 'back': tensor(0.0098),\n",
       " 'blue_sailor_collar': tensor(0.0098),\n",
       " 'light_smile': tensor(0.0097),\n",
       " 'open_mouth': tensor(0.0095),\n",
       " 'bird': tensor(0.0094),\n",
       " 'dated': tensor(0.0091),\n",
       " 'thighhighs': tensor(0.0090),\n",
       " 'long_hair': tensor(0.0087),\n",
       " 'facing_to_the_side': tensor(0.0087),\n",
       " 'wooden_fence': tensor(0.0086),\n",
       " 'twitter_username': tensor(0.0086),\n",
       " 'pale_skin': tensor(0.0086),\n",
       " 'railroad_crossing': tensor(0.0085),\n",
       " 'summer': tensor(0.0084),\n",
       " 'limited_palette': tensor(0.0084),\n",
       " 'cliff': tensor(0.0083),\n",
       " 'puffy_sleeves': tensor(0.0083),\n",
       " 'hair_behind_ear': tensor(0.0081),\n",
       " 'red_shirt': tensor(0.0081),\n",
       " 'cup': tensor(0.0077),\n",
       " 'looking_up': tensor(0.0075),\n",
       " 'rice_paddy': tensor(0.0075),\n",
       " 'dawn': tensor(0.0074),\n",
       " 'collared_shirt': tensor(0.0073),\n",
       " 'earrings': tensor(0.0071),\n",
       " 'brown_dress': tensor(0.0068),\n",
       " 'on_roof': tensor(0.0067),\n",
       " 'colored_skin': tensor(0.0067),\n",
       " 'watermark': tensor(0.0066),\n",
       " 'school_bag': tensor(0.0064),\n",
       " 'small_breasts': tensor(0.0063),\n",
       " 'on_railing': tensor(0.0063),\n",
       " 'cover': tensor(0.0062),\n",
       " 'outstretched_arms': tensor(0.0062),\n",
       " 'light_blush': tensor(0.0061),\n",
       " 'leaning_on_object': tensor(0.0061),\n",
       " 'pantyhose': tensor(0.0060),\n",
       " 'grey_eyes': tensor(0.0058),\n",
       " 'loose_hair_strand': tensor(0.0058),\n",
       " 'stairs': tensor(0.0057),\n",
       " 'silhouette': tensor(0.0057),\n",
       " 'muted_color': tensor(0.0056),\n",
       " 'dress': tensor(0.0055),\n",
       " 'ribbon': tensor(0.0055),\n",
       " 'grass': tensor(0.0055),\n",
       " 'long_bangs': tensor(0.0054),\n",
       " 'sand': tensor(0.0053),\n",
       " 'drink': tensor(0.0052),\n",
       " 'jewelry': tensor(0.0052),\n",
       " 'floating_clothes': tensor(0.0051),\n",
       " 'sideways_glance': tensor(0.0049),\n",
       " 'bow': tensor(0.0049),\n",
       " 'painting_(medium)': tensor(0.0048),\n",
       " 'red_eyes': tensor(0.0048),\n",
       " 'purple_eyes': tensor(0.0047),\n",
       " 'blurry_background': tensor(0.0047),\n",
       " 'white_pantyhose': tensor(0.0045),\n",
       " 'morning': tensor(0.0045),\n",
       " 'facing_viewer': tensor(0.0045),\n",
       " 'leaning_back': tensor(0.0045),\n",
       " 'table': tensor(0.0045),\n",
       " 'overcast': tensor(0.0044),\n",
       " 'can': tensor(0.0044),\n",
       " 'white_thighhighs': tensor(0.0043),\n",
       " 'dark_clouds': tensor(0.0043),\n",
       " ':|': tensor(0.0042),\n",
       " 'ascot': tensor(0.0040),\n",
       " 'faux_traditional_media': tensor(0.0039),\n",
       " 'medium_breasts': tensor(0.0038),\n",
       " 'ligne_claire': tensor(0.0038),\n",
       " 'sign': tensor(0.0037),\n",
       " 'eyelashes': tensor(0.0037),\n",
       " 'orange_background': tensor(0.0037),\n",
       " 'depth_of_field': tensor(0.0037),\n",
       " 'white_sky': tensor(0.0036),\n",
       " 'swept_bangs': tensor(0.0035),\n",
       " 'white_neckerchief': tensor(0.0035),\n",
       " 'brown_neckerchief': tensor(0.0034),\n",
       " 'castle': tensor(0.0034),\n",
       " 'socks': tensor(0.0034),\n",
       " 'pink_sky': tensor(0.0034),\n",
       " 'blue_skirt': tensor(0.0033),\n",
       " 'railroad_tracks': tensor(0.0033),\n",
       " 'hands_up': tensor(0.0033),\n",
       " 'messy_hair': tensor(0.0031),\n",
       " 'wine_bottle': tensor(0.0031),\n",
       " 'sailor_dress': tensor(0.0030),\n",
       " 'bare_legs': tensor(0.0030),\n",
       " 'light_frown': tensor(0.0030),\n",
       " 'blunt_bangs': tensor(0.0030),\n",
       " 'green_eyes': tensor(0.0029),\n",
       " 'sideways_mouth': tensor(0.0029),\n",
       " 'black_dress': tensor(0.0029),\n",
       " 'hand_up': tensor(0.0029),\n",
       " 'high-waist_skirt': tensor(0.0028),\n",
       " 'white_stripes': tensor(0.0028),\n",
       " 'blue_serafuku': tensor(0.0028),\n",
       " 'rock': tensor(0.0028),\n",
       " 'clock_tower': tensor(0.0028),\n",
       " 'nature': tensor(0.0028),\n",
       " 'mount_fuji': tensor(0.0027),\n",
       " 'mole': tensor(0.0027),\n",
       " 'frown': tensor(0.0027),\n",
       " 'hair_ornament': tensor(0.0027),\n",
       " 'sepia': tensor(0.0026),\n",
       " 'pleated_dress': tensor(0.0026),\n",
       " 'own_hands_together': tensor(0.0026),\n",
       " 'light_particles': tensor(0.0026),\n",
       " 'ripples': tensor(0.0026),\n",
       " 'monochrome': tensor(0.0026),\n",
       " 'fog': tensor(0.0025),\n",
       " 'acrylic_paint_(medium)': tensor(0.0025),\n",
       " 'wind_turbine': tensor(0.0025),\n",
       " 'mirror': tensor(0.0025),\n",
       " 'sketch': tensor(0.0025),\n",
       " 'cover_image': tensor(0.0025),\n",
       " 'floating': tensor(0.0025),\n",
       " 'brown_theme': tensor(0.0024),\n",
       " 'ass': tensor(0.0024),\n",
       " 'arm_at_side': tensor(0.0024),\n",
       " 'nape': tensor(0.0024),\n",
       " 'leaning_forward': tensor(0.0023),\n",
       " 'artist_logo': tensor(0.0023),\n",
       " 'chromatic_aberration': tensor(0.0023),\n",
       " 'plant': tensor(0.0023),\n",
       " 'transparent': tensor(0.0022),\n",
       " 'mole_under_eye': tensor(0.0022),\n",
       " 'street': tensor(0.0022),\n",
       " 'sake_bottle': tensor(0.0022),\n",
       " 'choppy_bangs': tensor(0.0022),\n",
       " 'zettai_ryouiki': tensor(0.0022),\n",
       " 'shirt_tucked_in': tensor(0.0022),\n",
       " 'album_cover': tensor(0.0022),\n",
       " 'windmill': tensor(0.0022),\n",
       " 'winter_uniform': tensor(0.0021),\n",
       " 'balancing': tensor(0.0021),\n",
       " 'surreal': tensor(0.0021),\n",
       " 'simple_background': tensor(0.0021),\n",
       " 'single_stripe': tensor(0.0021),\n",
       " 'fingernails': tensor(0.0021),\n",
       " 'tears': tensor(0.0020),\n",
       " 'yellow_eyes': tensor(0.0020),\n",
       " 'jar': tensor(0.0020),\n",
       " 'skirt_set': tensor(0.0020),\n",
       " 'moon': tensor(0.0020),\n",
       " 'painterly': tensor(0.0020),\n",
       " 'looking_down': tensor(0.0020),\n",
       " 'skyscraper': tensor(0.0019),\n",
       " 'grey_neckerchief': tensor(0.0019),\n",
       " 'sleeves_past_wrists': tensor(0.0019),\n",
       " 'no_pupils': tensor(0.0019),\n",
       " 'blue_necktie': tensor(0.0019),\n",
       " 'village': tensor(0.0019),\n",
       " 'orange_eyes': tensor(0.0019),\n",
       " 'jacket': tensor(0.0018),\n",
       " 'upper_body': tensor(0.0018),\n",
       " 'photo_background': tensor(0.0018),\n",
       " 'purple_skirt': tensor(0.0018),\n",
       " 'blue_hair': tensor(0.0018),\n",
       " 'shade': tensor(0.0018),\n",
       " 'star_(sky)': tensor(0.0018),\n",
       " 'thigh_gap': tensor(0.0018),\n",
       " 'outstretched_arm': tensor(0.0018),\n",
       " 'night': tensor(0.0017),\n",
       " 'glass': tensor(0.0017),\n",
       " 'contrail': tensor(0.0017),\n",
       " 'black_thighhighs': tensor(0.0017),\n",
       " 'skirt_lift': tensor(0.0017),\n",
       " 'white_skin': tensor(0.0017),\n",
       " 'plaid': tensor(0.0017),\n",
       " 'bench': tensor(0.0017),\n",
       " 'alcohol': tensor(0.0017),\n",
       " 'window': tensor(0.0016),\n",
       " 'rural': tensor(0.0016),\n",
       " 'crying': tensor(0.0016),\n",
       " 'running': tensor(0.0016),\n",
       " 'parted_bangs': tensor(0.0016),\n",
       " 'ferris_wheel': tensor(0.0016),\n",
       " 'bucket': tensor(0.0016),\n",
       " 'grey_shirt': tensor(0.0016),\n",
       " 'real_world_location': tensor(0.0016),\n",
       " 'red_sailor_collar': tensor(0.0016),\n",
       " 'virtual_youtuber': tensor(0.0016),\n",
       " 'purple_sailor_collar': tensor(0.0016),\n",
       " 'eyebrows_hidden_by_hair': tensor(0.0015),\n",
       " 'drinking_glass': tensor(0.0015),\n",
       " 'umbrella': tensor(0.0015),\n",
       " 'bicycle': tensor(0.0015),\n",
       " 'very_short_hair': tensor(0.0015),\n",
       " 'city_lights': tensor(0.0015),\n",
       " 'road_sign': tensor(0.0015),\n",
       " 'flower': tensor(0.0015),\n",
       " 'fantasy': tensor(0.0015),\n",
       " 'border': tensor(0.0015),\n",
       " 'purple_hair': tensor(0.0015),\n",
       " 'blunt_ends': tensor(0.0015),\n",
       " 'looking_at_another': tensor(0.0015),\n",
       " 'blonde_hair': tensor(0.0015),\n",
       " 'sitting': tensor(0.0015),\n",
       " 'partially_submerged': tensor(0.0014),\n",
       " 'short_sleeves': tensor(0.0014),\n",
       " 'watercolor_(medium)': tensor(0.0014),\n",
       " 'long_skirt': tensor(0.0014),\n",
       " 'blue_theme': tensor(0.0014),\n",
       " 'chimney': tensor(0.0014),\n",
       " 'book': tensor(0.0014),\n",
       " 'dark': tensor(0.0014),\n",
       " 'clothes_lift': tensor(0.0014),\n",
       " 'light_rays': tensor(0.0014),\n",
       " 'rust': tensor(0.0014),\n",
       " 'plaid_skirt': tensor(0.0014),\n",
       " 'teeth': tensor(0.0014),\n",
       " 'cover_page': tensor(0.0014),\n",
       " 'straight_hair': tensor(0.0014),\n",
       " 'red_theme': tensor(0.0014),\n",
       " 'half-closed_eyes': tensor(0.0014),\n",
       " 'soda_bottle': tensor(0.0013),\n",
       " 'kitauji_high_school_uniform': tensor(0.0013),\n",
       " 'earphones': tensor(0.0013),\n",
       " 'chain-link_fence': tensor(0.0013),\n",
       " 'sailor': tensor(0.0013),\n",
       " 'radio_antenna': tensor(0.0013),\n",
       " 'cross': tensor(0.0013),\n",
       " 'lens_flare': tensor(0.0013),\n",
       " 'cropped_legs': tensor(0.0013),\n",
       " 'see-through_silhouette': tensor(0.0013),\n",
       " 'purple_shirt': tensor(0.0013),\n",
       " 'phone': tensor(0.0013),\n",
       " 'official_alternate_costume': tensor(0.0013),\n",
       " 'train': tensor(0.0012),\n",
       " 'yellow_background': tensor(0.0012),\n",
       " 'architecture': tensor(0.0012),\n",
       " 'flying': tensor(0.0012),\n",
       " 'chair': tensor(0.0012),\n",
       " 'bush': tensor(0.0012),\n",
       " 'yellow_theme': tensor(0.0012),\n",
       " 'leaning': tensor(0.0012),\n",
       " 'alternate_costume': tensor(0.0012),\n",
       " 'grey_hair': tensor(0.0012),\n",
       " 'arms_behind_back': tensor(0.0012),\n",
       " 'ladder': tensor(0.0011),\n",
       " 'drink_can': tensor(0.0011),\n",
       " 'raised_eyebrows': tensor(0.0011),\n",
       " 'sidelighting': tensor(0.0011),\n",
       " 'water_drop': tensor(0.0011),\n",
       " 'hat': tensor(0.0011),\n",
       " 'hairclip': tensor(0.0011),\n",
       " 'full_body': tensor(0.0011),\n",
       " 'frills': tensor(0.0011),\n",
       " 'seagull': tensor(0.0011),\n",
       " 'backpack': tensor(0.0011),\n",
       " 'path': tensor(0.0011),\n",
       " 'pole': tensor(0.0011),\n",
       " 'flat_chest': tensor(0.0011),\n",
       " 'white_socks': tensor(0.0011),\n",
       " 'camera': tensor(0.0011),\n",
       " 'kneehighs': tensor(0.0011),\n",
       " 'purple_ribbon': tensor(0.0011),\n",
       " 'copyright_name': tensor(0.0011),\n",
       " 'smoke': tensor(0.0011),\n",
       " 'drinking_straw': tensor(0.0011),\n",
       " 'floating_object': tensor(0.0011),\n",
       " 'english_text': tensor(0.0010),\n",
       " 'tareme': tensor(0.0010),\n",
       " 'collar': tensor(0.0010),\n",
       " 'ahoge': tensor(0.0010),\n",
       " 'empty_eyes': tensor(0.0010),\n",
       " 'gloves': tensor(0.0010),\n",
       " 'collarbone': tensor(0.0010),\n",
       " 'shoes': tensor(0.0010),\n",
       " 'graphite_(medium)': tensor(0.0010),\n",
       " 'fishing_rod': tensor(0.0010),\n",
       " 'spread_arms': tensor(0.0010),\n",
       " 'white_serafuku': tensor(0.0010),\n",
       " 'bowtie': tensor(0.0010),\n",
       " 'black_socks': tensor(0.0010),\n",
       " 'ponytail': tensor(0.0010),\n",
       " 'grey_serafuku': tensor(0.0010),\n",
       " 'brown_jacket': tensor(0.0010),\n",
       " 'ruins': tensor(0.0010),\n",
       " 'grey_skirt': tensor(0.0010),\n",
       " 'serious': tensor(0.0010),\n",
       " 'lips': tensor(0.0010),\n",
       " 'dot_nose': tensor(0.0010),\n",
       " 'rating:questionable': tensor(0.0010),\n",
       " 'sad': tensor(0.0009),\n",
       " 'multicolored_hair': tensor(0.0009),\n",
       " 'aircraft': tensor(0.0009),\n",
       " 'bare_shoulders': tensor(0.0009),\n",
       " 'night_sky': tensor(0.0009),\n",
       " 'perfume_bottle': tensor(0.0009),\n",
       " 'blue_shirt': tensor(0.0009),\n",
       " 'clear_sky': tensor(0.0009),\n",
       " 'animal': tensor(0.0009),\n",
       " 'hatching_(texture)': tensor(0.0009),\n",
       " 'indoors': tensor(0.0009),\n",
       " 'neck_ribbon': tensor(0.0009),\n",
       " 'red_dress': tensor(0.0009),\n",
       " 'caustics': tensor(0.0009),\n",
       " 'black_footwear': tensor(0.0009),\n",
       " 'fisheye': tensor(0.0009),\n",
       " 'undershirt': tensor(0.0009),\n",
       " 'purple_bow': tensor(0.0009),\n",
       " 'stud_earrings': tensor(0.0009),\n",
       " ':o': tensor(0.0009),\n",
       " '1boy': tensor(0.0009),\n",
       " 'dot_mouth': tensor(0.0009),\n",
       " 'towel': tensor(0.0009),\n",
       " '1other': tensor(0.0009),\n",
       " 'container': tensor(0.0009),\n",
       " 'gate': tensor(0.0009),\n",
       " 'watch': tensor(0.0009),\n",
       " 'sleeveless': tensor(0.0008),\n",
       " 'leaf': tensor(0.0008),\n",
       " 'car': tensor(0.0008),\n",
       " 'glowing': tensor(0.0008),\n",
       " 'frilled_skirt': tensor(0.0008),\n",
       " 'pool': tensor(0.0008),\n",
       " 'large_breasts': tensor(0.0008),\n",
       " 'buttons': tensor(0.0008),\n",
       " 'military': tensor(0.0008),\n",
       " 'white_background': tensor(0.0008),\n",
       " 'abstract_background': tensor(0.0008),\n",
       " 'motor_vehicle': tensor(0.0008),\n",
       " 'lifebuoy': tensor(0.0008),\n",
       " 'orange_hair': tensor(0.0008),\n",
       " 'millipen_(medium)': tensor(0.0008),\n",
       " 'belt': tensor(0.0008),\n",
       " 'shoulder_bag': tensor(0.0008),\n",
       " 'outstretched_hand': tensor(0.0008),\n",
       " 'smokestack': tensor(0.0008),\n",
       " 'black_pantyhose': tensor(0.0008),\n",
       " 'nib_pen_(medium)': tensor(0.0008),\n",
       " 'ice': tensor(0.0008),\n",
       " 'purple_serafuku': tensor(0.0008),\n",
       " 'multiple_girls': tensor(0.0008),\n",
       " 'light': tensor(0.0008),\n",
       " 'sweat': tensor(0.0008),\n",
       " 'arm_up': tensor(0.0008),\n",
       " 'arm_rest': tensor(0.0008),\n",
       " 'lantern': tensor(0.0007),\n",
       " '^_^': tensor(0.0007),\n",
       " 'soda_can': tensor(0.0007),\n",
       " 'weapon': tensor(0.0007),\n",
       " 'fish': tensor(0.0007),\n",
       " 'blue_bow': tensor(0.0007),\n",
       " 'cable': tensor(0.0007),\n",
       " 'paper': tensor(0.0007),\n",
       " 'basket': tensor(0.0007),\n",
       " 'flask': tensor(0.0007),\n",
       " 'braid': tensor(0.0007),\n",
       " 'airplane': tensor(0.0007),\n",
       " 'starry_sky': tensor(0.0007),\n",
       " 'cellphone': tensor(0.0007),\n",
       " 'underwear': tensor(0.0007),\n",
       " 'pointing': tensor(0.0007),\n",
       " 'splashing': tensor(0.0007),\n",
       " 'blue_ribbon': tensor(0.0007),\n",
       " 'legs': tensor(0.0007),\n",
       " 'instrument': tensor(0.0007),\n",
       " 'striped_clothes': tensor(0.0007),\n",
       " 'food': tensor(0.0007),\n",
       " 'blurry_foreground': tensor(0.0007),\n",
       " 'androgynous': tensor(0.0007),\n",
       " 'product_placement': tensor(0.0007),\n",
       " 'dress_shirt': tensor(0.0007),\n",
       " 'purple_sky': tensor(0.0007),\n",
       " 'industrial_pipe': tensor(0.0007),\n",
       " 'no_mouth': tensor(0.0007),\n",
       " 'straight-on': tensor(0.0007),\n",
       " 'brown_bag': tensor(0.0007),\n",
       " 'happy': tensor(0.0007),\n",
       " 'hairband': tensor(0.0007),\n",
       " 'hair_over_eyes': tensor(0.0007),\n",
       " 'military_uniform': tensor(0.0006),\n",
       " 'mixed_media': tensor(0.0006),\n",
       " 'solo_focus': tensor(0.0006),\n",
       " 'one_eye_closed': tensor(0.0006),\n",
       " 'vanishing_point': tensor(0.0006),\n",
       " 'open_clothes': tensor(0.0006),\n",
       " 'teardrop': tensor(0.0006),\n",
       " 'black_jacket': tensor(0.0006),\n",
       " 'red_hair': tensor(0.0006),\n",
       " 'heart': tensor(0.0006),\n",
       " 'forest': tensor(0.0006),\n",
       " 'animal_ears': tensor(0.0006),\n",
       " 'sweater': tensor(0.0006),\n",
       " 'arms_up': tensor(0.0006),\n",
       " 'cardigan': tensor(0.0006),\n",
       " 'thermos': tensor(0.0006),\n",
       " 'multicolored_clothes': tensor(0.0006),\n",
       " 'white_border': tensor(0.0006),\n",
       " 'soda': tensor(0.0006),\n",
       " 'shaded_face': tensor(0.0006),\n",
       " 'vase': tensor(0.0006),\n",
       " 'air_conditioner': tensor(0.0006),\n",
       " 'trash_can': tensor(0.0006),\n",
       " 'vest': tensor(0.0006),\n",
       " 'disposable_cup': tensor(0.0006),\n",
       " 'tube': tensor(0.0006),\n",
       " 'white_hair': tensor(0.0006),\n",
       " 'stream': tensor(0.0006),\n",
       " 'field': tensor(0.0006),\n",
       " 'school': tensor(0.0006),\n",
       " 'holding_drink': tensor(0.0006),\n",
       " 'brown_footwear': tensor(0.0006),\n",
       " 'reaching': tensor(0.0006),\n",
       " 'pink_neckerchief': tensor(0.0006),\n",
       " 'brown_cardigan': tensor(0.0006),\n",
       " 'ghost': tensor(0.0006),\n",
       " 'drinking': tensor(0.0006),\n",
       " 'very_long_hair': tensor(0.0006),\n",
       " 'open_hand': tensor(0.0006),\n",
       " 'volcano': tensor(0.0006),\n",
       " 'shorts': tensor(0.0006),\n",
       " 'juliet_sleeves': tensor(0.0005),\n",
       " 'midriff': tensor(0.0005),\n",
       " 'pink_eyes': tensor(0.0005),\n",
       " 'sparkle': tensor(0.0005),\n",
       " 'split_mouth': tensor(0.0005),\n",
       " 'sweatdrop': tensor(0.0005),\n",
       " 'colored_pencil_(medium)': tensor(0.0005),\n",
       " 'midriff_peek': tensor(0.0005),\n",
       " 'open_hands': tensor(0.0005),\n",
       " 'tokkuri': tensor(0.0005),\n",
       " 'pocket': tensor(0.0005),\n",
       " 'orange_shirt': tensor(0.0005),\n",
       " 'vending_machine': tensor(0.0005),\n",
       " 'sunbeam': tensor(0.0005),\n",
       " 'glasses': tensor(0.0005),\n",
       " 'green_skirt': tensor(0.0005),\n",
       " 'cactus': tensor(0.0005),\n",
       " 'greyscale': tensor(0.0005),\n",
       " 'pagoda': tensor(0.0005),\n",
       " 'cork': tensor(0.0005),\n",
       " 'light_brown_hair': tensor(0.0005),\n",
       " 'aged_down': tensor(0.0005),\n",
       " 'brown_sweater': tensor(0.0005),\n",
       " 'twintails': tensor(0.0005),\n",
       " 'turtleneck': tensor(0.0005),\n",
       " 'detached_sleeves': tensor(0.0005),\n",
       " 'two-sided_skirt': tensor(0.0005),\n",
       " 'compass': tensor(0.0005),\n",
       " 'dragonfly': tensor(0.0005),\n",
       " 'ear_piercing': tensor(0.0005),\n",
       " 'colored_inner_hair': tensor(0.0005),\n",
       " 'legs_apart': tensor(0.0005),\n",
       " 'beer_bottle': tensor(0.0005),\n",
       " 'door': tensor(0.0005),\n",
       " 'novel_cover': tensor(0.0005),\n",
       " 'halo': tensor(0.0005),\n",
       " 'radio': tensor(0.0005),\n",
       " 'marker_(medium)': tensor(0.0005),\n",
       " 'carrying': tensor(0.0005),\n",
       " 'brown_background': tensor(0.0005),\n",
       " 'polka_dot': tensor(0.0005),\n",
       " 'torii': tensor(0.0005),\n",
       " 'wide_sleeves': tensor(0.0005),\n",
       " 'surprised': tensor(0.0005),\n",
       " 'very_wide_shot': tensor(0.0005),\n",
       " 'rain': tensor(0.0005),\n",
       " 'aqua_eyes': tensor(0.0005),\n",
       " 'hair_over_one_eye': tensor(0.0005),\n",
       " 'grey_sailor_collar': tensor(0.0005),\n",
       " 'gradient_hair': tensor(0.0005),\n",
       " 'hair_ribbon': tensor(0.0005),\n",
       " 'white_skirt': tensor(0.0005),\n",
       " 'autumn': tensor(0.0005),\n",
       " 'nose': tensor(0.0005),\n",
       " '2girls': tensor(0.0005),\n",
       " 'makeup': tensor(0.0005),\n",
       " 'two-tone_skirt': tensor(0.0005),\n",
       " 'suicide': tensor(0.0005),\n",
       " 'bare_arms': tensor(0.0005),\n",
       " 'wet': tensor(0.0005),\n",
       " 'star_(symbol)': tensor(0.0005),\n",
       " 'steam': tensor(0.0005),\n",
       " 'soap_bottle': tensor(0.0005),\n",
       " 'blue_skin': tensor(0.0005),\n",
       " 'piercing': tensor(0.0005),\n",
       " 'retro_artstyle': tensor(0.0005),\n",
       " 'holding_cup': tensor(0.0005),\n",
       " 'vignetting': tensor(0.0005),\n",
       " 'head_rest': tensor(0.0005),\n",
       " 'covered_eyes': tensor(0.0004),\n",
       " 'white_eyes': tensor(0.0004),\n",
       " 'apartment': tensor(0.0004),\n",
       " 'desk': tensor(0.0004),\n",
       " 'box': tensor(0.0004),\n",
       " 'partially_colored': tensor(0.0004),\n",
       " 'pink_shirt': tensor(0.0004),\n",
       " 'black_ribbon': tensor(0.0004),\n",
       " 'traffic_light': tensor(0.0004),\n",
       " 'cat': tensor(0.0004),\n",
       " 'lamp': tensor(0.0004),\n",
       " 'flock': tensor(0.0004),\n",
       " 'drum_(container)': tensor(0.0004),\n",
       " 'liquid': tensor(0.0004),\n",
       " 'swim_ring': tensor(0.0004),\n",
       " 'short_dress': tensor(0.0004),\n",
       " 'green_hair': tensor(0.0004),\n",
       " 'kneepits': tensor(0.0004),\n",
       " 'lotion_bottle': tensor(0.0004),\n",
       " 'tail': tensor(0.0004),\n",
       " 'black_sleeves': tensor(0.0004),\n",
       " 'looking_at_object': tensor(0.0004),\n",
       " 'bubble': tensor(0.0004),\n",
       " 'white_gloves': tensor(0.0004),\n",
       " 'hair_intakes': tensor(0.0004),\n",
       " 'see-through': tensor(0.0004),\n",
       " 'antenna_hair': tensor(0.0004),\n",
       " 'branch': tensor(0.0004),\n",
       " 'motion_blur': tensor(0.0004),\n",
       " 'crying_with_eyes_open': tensor(0.0004),\n",
       " 'male_focus': tensor(0.0004),\n",
       " 'purple_necktie': tensor(0.0004),\n",
       " 'fire': tensor(0.0004),\n",
       " 'clenched_hand': tensor(0.0004),\n",
       " 'from_above': tensor(0.0004),\n",
       " 'parody': tensor(0.0004),\n",
       " 'yellow_neckerchief': tensor(0.0004),\n",
       " 'purple_bowtie': tensor(0.0004),\n",
       " 'full_moon': tensor(0.0004),\n",
       " 'scarf': tensor(0.0004),\n",
       " 'hair_tie': tensor(0.0004),\n",
       " ':d': tensor(0.0004),\n",
       " 'yellow_skirt': tensor(0.0004),\n",
       " 'double_horizontal_stripe': tensor(0.0004),\n",
       " 'different_reflection': tensor(0.0004),\n",
       " 'standing_on_one_leg': tensor(0.0004),\n",
       " 'hair_bow': tensor(0.0004),\n",
       " 'black_undershirt': tensor(0.0004),\n",
       " 'black_bag': tensor(0.0004),\n",
       " 'red_ribbon': tensor(0.0004),\n",
       " 'foreshortening': tensor(0.0004),\n",
       " 'cola': tensor(0.0004),\n",
       " 'smartphone': tensor(0.0004),\n",
       " 'wings': tensor(0.0004),\n",
       " 'panties': tensor(0.0004),\n",
       " 'milk': tensor(0.0004),\n",
       " 'skindentation': tensor(0.0004),\n",
       " 'barefoot': tensor(0.0004),\n",
       " 'clenched_hands': tensor(0.0004),\n",
       " 'flag': tensor(0.0004),\n",
       " 'pink_hair': tensor(0.0004),\n",
       " 'footprints': tensor(0.0004),\n",
       " 'notebook': tensor(0.0004),\n",
       " 'skirt_hold': tensor(0.0004),\n",
       " 'pointy_ears': tensor(0.0003),\n",
       " 'green_neckerchief': tensor(0.0003),\n",
       " 'copyright_notice': tensor(0.0003),\n",
       " 'brown_vest': tensor(0.0003),\n",
       " 'crossed_legs': tensor(0.0003),\n",
       " 'blue_bowtie': tensor(0.0003),\n",
       " 'one-hour_drawing_challenge': tensor(0.0003),\n",
       " 'glint': tensor(0.0003),\n",
       " 'breath': tensor(0.0003),\n",
       " 'green_sailor_collar': tensor(0.0003),\n",
       " 'sanpaku': tensor(0.0003),\n",
       " 'earbuds': tensor(0.0003),\n",
       " 'two-tone_hair': tensor(0.0003),\n",
       " 'white_sleeves': tensor(0.0003),\n",
       " 'red_bow': tensor(0.0003),\n",
       " 'two-sided_fabric': tensor(0.0003),\n",
       " 'black_bow': tensor(0.0003),\n",
       " 'music': tensor(0.0003),\n",
       " 'east_asian_architecture': tensor(0.0003),\n",
       " 'crossed_bangs': tensor(0.0003),\n",
       " 'juice_box': tensor(0.0003),\n",
       " 'whale': tensor(0.0003),\n",
       " 'tire': tensor(0.0003),\n",
       " 'weibo_username': tensor(0.0003),\n",
       " 'sleeves_past_elbows': tensor(0.0003),\n",
       " 'bright_pupils': tensor(0.0003),\n",
       " 'circle_skirt': tensor(0.0003),\n",
       " 'pants': tensor(0.0003),\n",
       " 'arch': tensor(0.0003),\n",
       " 'wide-eyed': tensor(0.0003),\n",
       " 'rose': tensor(0.0003),\n",
       " 'twisted_torso': tensor(0.0003),\n",
       " '>_<': tensor(0.0003),\n",
       " ':3': tensor(0.0003),\n",
       " 'roman_numeral': tensor(0.0003),\n",
       " 'squatting': tensor(0.0003),\n",
       " 'coat': tensor(0.0003),\n",
       " 'elbow_rest': tensor(0.0003),\n",
       " 'comic': tensor(0.0003),\n",
       " 'doujin_cover': tensor(0.0003),\n",
       " 'pursed_lips': tensor(0.0003),\n",
       " 'depressed': tensor(0.0003),\n",
       " 'giant': tensor(0.0003),\n",
       " 'striped_skirt': tensor(0.0003),\n",
       " 'dark_skin': tensor(0.0003),\n",
       " 'analog_clock': tensor(0.0003),\n",
       " 'juice': tensor(0.0003),\n",
       " 'looking_outside': tensor(0.0003),\n",
       " 'dripping': tensor(0.0003),\n",
       " 'holding_bag': tensor(0.0003),\n",
       " 'white_pupils': tensor(0.0003),\n",
       " 'rope': tensor(0.0003),\n",
       " 'double-parted_bangs': tensor(0.0003),\n",
       " 'official_alternate_hairstyle': tensor(0.0003),\n",
       " 'brown_sleeves': tensor(0.0003),\n",
       " 'tan': tensor(0.0003),\n",
       " 'blue_ascot': tensor(0.0003),\n",
       " 'waterfall': tensor(0.0003),\n",
       " 'sleeves_rolled_up': tensor(0.0003),\n",
       " 'dappled_sunlight': tensor(0.0003),\n",
       " 'one_eye_covered': tensor(0.0003),\n",
       " 'bandaid': tensor(0.0003),\n",
       " 'pond': tensor(0.0003),\n",
       " 'gem': tensor(0.0003),\n",
       " 'milk_bottle': tensor(0.0003),\n",
       " 'church': tensor(0.0003),\n",
       " 'winter': tensor(0.0003),\n",
       " 'cigarette': tensor(0.0003),\n",
       " 'desert': tensor(0.0003),\n",
       " 'oar': tensor(0.0003),\n",
       " 'billboard': tensor(0.0003),\n",
       " 'sleeveless_shirt': tensor(0.0003),\n",
       " 'fringe_trim': tensor(0.0003),\n",
       " 'head_tilt': tensor(0.0003),\n",
       " 'jitome': tensor(0.0003),\n",
       " 'multicolored_eyes': tensor(0.0003),\n",
       " 'blush_stickers': tensor(0.0003),\n",
       " 'string': tensor(0.0003),\n",
       " 'wood': tensor(0.0003),\n",
       " 'brown_shorts': tensor(0.0003),\n",
       " 'school_desk': tensor(0.0003),\n",
       " 'streaked_hair': tensor(0.0003),\n",
       " 'contrapposto': tensor(0.0003),\n",
       " 'plastic_bag': tensor(0.0003),\n",
       " 'navel': tensor(0.0003),\n",
       " 'bandages': tensor(0.0003),\n",
       " 'standing_on_liquid': tensor(0.0003),\n",
       " 'fishing': tensor(0.0003),\n",
       " 'from_below': tensor(0.0003),\n",
       " 'blue_bag': tensor(0.0003),\n",
       " 'people': tensor(0.0003),\n",
       " 'furrowed_brow': tensor(0.0003),\n",
       " 'no_humans': tensor(0.0003),\n",
       " 'monochrome_background': tensor(0.0003),\n",
       " 'weibo_logo': tensor(0.0003),\n",
       " 'swimsuit': tensor(0.0003),\n",
       " 'bug': tensor(0.0003),\n",
       " 'pink_skirt': tensor(0.0003),\n",
       " 'post-apocalypse': tensor(0.0003),\n",
       " 'no_legwear': tensor(0.0003),\n",
       " 'teacup': tensor(0.0003),\n",
       " 'grin': tensor(0.0003),\n",
       " 'outside_border': tensor(0.0003),\n",
       " 'unworn_headwear': tensor(0.0003),\n",
       " 'shoulder_blades': tensor(0.0003),\n",
       " 'hand_on_own_hip': tensor(0.0003),\n",
       " 'character_name': tensor(0.0003),\n",
       " 'fine_art_parody': tensor(0.0003),\n",
       " 'w_arms': tensor(0.0003),\n",
       " 'airship': tensor(0.0003),\n",
       " 'yellow_shirt': tensor(0.0003),\n",
       " 'map': tensor(0.0003),\n",
       " 'playground': tensor(0.0003),\n",
       " 'ball': tensor(0.0003),\n",
       " 'nail_polish': tensor(0.0003),\n",
       " 'fruit': tensor(0.0003),\n",
       " 'pink_theme': tensor(0.0003),\n",
       " 'kamiyama_high_school_uniform_(hyouka)': tensor(0.0003),\n",
       " 'torn_clothes': tensor(0.0003),\n",
       " 'tongue': tensor(0.0003),\n",
       " 'layered_clothes': tensor(0.0003),\n",
       " 'hourglass': tensor(0.0003),\n",
       " 'web_address': tensor(0.0002),\n",
       " 'tearing_up': tensor(0.0002),\n",
       " 'choker': tensor(0.0002),\n",
       " 'purple_theme': tensor(0.0002),\n",
       " 'alternate_hair_length': tensor(0.0002),\n",
       " 'beer': tensor(0.0002),\n",
       " 'child': tensor(0.0002),\n",
       " 'dutch_angle': tensor(0.0002),\n",
       " 'school_briefcase': tensor(0.0002),\n",
       " 'storm': tensor(0.0002),\n",
       " 'thick_thighs': tensor(0.0002),\n",
       " 'looking_at_mirror': tensor(0.0002),\n",
       " 'loafers': tensor(0.0002),\n",
       " 'hair_bun': tensor(0.0002),\n",
       " 'shoulder_strap': tensor(0.0002),\n",
       " 'pov': tensor(0.0002),\n",
       " 'condensation': tensor(0.0002),\n",
       " 'wristwatch': tensor(0.0002),\n",
       " 'upper_teeth_only': tensor(0.0002),\n",
       " 'handbag': tensor(0.0002),\n",
       " 'crop_top': tensor(0.0002),\n",
       " ':/': tensor(0.0002),\n",
       " 'headband': tensor(0.0002),\n",
       " 'park': tensor(0.0002),\n",
       " 'mole_under_mouth': tensor(0.0002),\n",
       " 'red_background': tensor(0.0002),\n",
       " 'wooden_floor': tensor(0.0002),\n",
       " 'crossed_arms': tensor(0.0002),\n",
       " 'fur_trim': tensor(0.0002),\n",
       " 'colored_sclera': tensor(0.0002),\n",
       " 'swing': tensor(0.0002),\n",
       " 'no_headwear': tensor(0.0002),\n",
       " 'fading': tensor(0.0002),\n",
       " 'black_cardigan': tensor(0.0002),\n",
       " 'black_vest': tensor(0.0002),\n",
       " 'wavy_hair': tensor(0.0002),\n",
       " 'high_collar': tensor(0.0002),\n",
       " 'back_bow': tensor(0.0002),\n",
       " 'shop': tensor(0.0002),\n",
       " 'bicycle_basket': tensor(0.0002),\n",
       " 'bags_under_eyes': tensor(0.0002),\n",
       " 'borrowed_character': tensor(0.0002),\n",
       " 'thigh_strap': tensor(0.0002),\n",
       " 'strap': tensor(0.0002),\n",
       " 'black_necktie': tensor(0.0002),\n",
       " 'gakuran': tensor(0.0002),\n",
       " 'hand_rest': tensor(0.0002),\n",
       " 'snow': tensor(0.0002),\n",
       " 'brick_wall': tensor(0.0002),\n",
       " 'breast_pocket': tensor(0.0002),\n",
       " 'character:tomoe_hotaru': tensor(0.0002),\n",
       " 'green_serafuku': tensor(0.0002),\n",
       " 'bare_tree': tensor(0.0002),\n",
       " 'alternate_hairstyle': tensor(0.0002),\n",
       " 'character:shinonome_ena': tensor(0.0002),\n",
       " 'u_u': tensor(0.0002),\n",
       " 'spot_color': tensor(0.0002),\n",
       " 'shiny_skin': tensor(0.0002),\n",
       " 'red_necktie': tensor(0.0002),\n",
       " 'headphones': tensor(0.0002),\n",
       " 'eyes_visible_through_hair': tensor(0.0002),\n",
       " 'sword': tensor(0.0002),\n",
       " 'letterboxed': tensor(0.0002),\n",
       " 'logo': tensor(0.0002),\n",
       " 'anchor_symbol': tensor(0.0002),\n",
       " 'yasogami_school_uniform': tensor(0.0002),\n",
       " 'aqua_neckerchief': tensor(0.0002),\n",
       " 'briefcase': tensor(0.0002),\n",
       " 'on_ground': tensor(0.0002),\n",
       " 'pom_pom_(clothes)': tensor(0.0002),\n",
       " 'black_headwear': tensor(0.0002),\n",
       " 'japanese_clothes': tensor(0.0002),\n",
       " 'giantess': tensor(0.0002),\n",
       " 'closed_umbrella': tensor(0.0002),\n",
       " 'potted_plant': tensor(0.0002),\n",
       " 'stone_wall': tensor(0.0002),\n",
       " 'antennae': tensor(0.0002),\n",
       " 'plate': tensor(0.0002),\n",
       " 'shell': tensor(0.0002),\n",
       " 'realistic': tensor(0.0002),\n",
       " 'banner': tensor(0.0002),\n",
       " 'white_footwear': tensor(0.0002),\n",
       " 'wire': tensor(0.0002),\n",
       " 'brown_headwear': tensor(0.0002),\n",
       " 'ambiguous_gender': tensor(0.0002),\n",
       " 'afloat': tensor(0.0002),\n",
       " 'colored_tips': tensor(0.0002),\n",
       " 'orange_skirt': tensor(0.0002),\n",
       " 'curtains': tensor(0.0002),\n",
       " 'leg_up': tensor(0.0002),\n",
       " 'painting_(object)': tensor(0.0002),\n",
       " 'capelet': tensor(0.0002),\n",
       " 'halftone': tensor(0.0002),\n",
       " 'blanket': tensor(0.0002),\n",
       " 'blank_eyes': tensor(0.0002),\n",
       " 'pillar': tensor(0.0002),\n",
       " 'wing_collar': tensor(0.0002),\n",
       " 'white_flower': tensor(0.0002),\n",
       " 'brown_gloves': tensor(0.0002),\n",
       " '2023': tensor(0.0002),\n",
       " 'tattoo': tensor(0.0002),\n",
       " 'legs_up': tensor(0.0002),\n",
       " 'bare_back': tensor(0.0002),\n",
       " 'holding_can': tensor(0.0002),\n",
       " 'arm_behind_back': tensor(0.0002),\n",
       " 'black_shorts': tensor(0.0002),\n",
       " 'dark_blue_hair': tensor(0.0002),\n",
       " 'shampoo_bottle': tensor(0.0002),\n",
       " 'single_earring': tensor(0.0002),\n",
       " 'gourd': tensor(0.0002),\n",
       " 'charm_(object)': tensor(0.0002),\n",
       " 'bowl': tensor(0.0002),\n",
       " 'puddle': tensor(0.0002),\n",
       " 'single_horizontal_stripe': tensor(0.0002),\n",
       " 'jumping': tensor(0.0002),\n",
       " 'wet_hair': tensor(0.0002),\n",
       " 'utaite': tensor(0.0002),\n",
       " 'broom': tensor(0.0002),\n",
       " 'foliage': tensor(0.0002),\n",
       " 'chess_piece': tensor(0.0002),\n",
       " 'choko_(cup)': tensor(0.0002),\n",
       " 'v_arms': tensor(0.0002),\n",
       " 'hand_on_table': tensor(0.0002),\n",
       " 'colorful': tensor(0.0002),\n",
       " 'black_gloves': tensor(0.0002),\n",
       " 'picture_frame': tensor(0.0002),\n",
       " 'new_year': tensor(0.0002),\n",
       " 'latin_cross': tensor(0.0002),\n",
       " 'white_headwear': tensor(0.0002),\n",
       " 'birthday': tensor(0.0002),\n",
       " 'photo_(object)': tensor(0.0002),\n",
       " 'horns': tensor(0.0002),\n",
       " 'black_ascot': tensor(0.0002),\n",
       " 'bokeh': tensor(0.0002),\n",
       " 'long_shirt': tensor(0.0002),\n",
       " 'nose_blush': tensor(0.0002),\n",
       " 'machinery': tensor(0.0002),\n",
       " 'binoculars': tensor(0.0002),\n",
       " 'flipped_hair': tensor(0.0002),\n",
       " 'clothes_pin': tensor(0.0002),\n",
       " 'character:mogami_(kancolle)': tensor(0.0002),\n",
       " 'floral_print': tensor(0.0002),\n",
       " 'microphone': tensor(0.0002),\n",
       " 'scissors': tensor(0.0002),\n",
       " 'pine_tree': tensor(0.0002),\n",
       " 'red_ascot': tensor(0.0002),\n",
       " 'palm_tree': tensor(0.0002),\n",
       " 'no_nose': tensor(0.0002),\n",
       " 'sake': tensor(0.0002),\n",
       " 'counter': tensor(0.0002),\n",
       " 'tassel': tensor(0.0002),\n",
       " 'artistic_error': tensor(0.0002),\n",
       " 'armband': tensor(0.0002),\n",
       " 'rating:explicit': tensor(0.0002),\n",
       " 'sash': tensor(0.0002),\n",
       " 'looking_at_animal': tensor(0.0002),\n",
       " 'tombstone': tensor(0.0002),\n",
       " 'light_bulb': tensor(0.0002),\n",
       " 'black_border': tensor(0.0002),\n",
       " 'short_hair_with_long_locks': tensor(0.0002),\n",
       " '1990s_(style)': tensor(0.0002),\n",
       " 'knife': tensor(0.0002),\n",
       " 'sidewalk': tensor(0.0002),\n",
       " 'hair_flower': tensor(0.0002),\n",
       " 'gold_trim': tensor(0.0002),\n",
       " 'black_nails': tensor(0.0002),\n",
       " 'suspenders': tensor(0.0002),\n",
       " 'holding_camera': tensor(0.0002),\n",
       " 'white_panties': tensor(0.0002),\n",
       " 'tray': tensor(0.0002),\n",
       " 'lipstick': tensor(0.0002),\n",
       " 'diffraction_spikes': tensor(0.0002),\n",
       " 'tiptoes': tensor(0.0002),\n",
       " 'pouring': tensor(0.0002),\n",
       " 'boots': tensor(0.0002),\n",
       " 'above_clouds': tensor(0.0002),\n",
       " 'median_furrow': tensor(0.0002),\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {model.config.id2label[i]: logit.float() for i, logit in enumerate(logits)}\n",
    "results = {\n",
    "    k: v for k, v in sorted(results.items(), key=lambda item: item[1], reverse=True)\n",
    "}\n",
    "results  # rating tags and character tags are also included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Swinv2ForImageClassification(\n",
       "  (swinv2): Swinv2Model(\n",
       "    (embeddings): Swinv2Embeddings(\n",
       "      (patch_embeddings): Swinv2PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Swinv2Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (key): Linear(in_features=128, out_features=128, bias=False)\n",
       "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (key): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (intermediate_act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-17): 18 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=False)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (intermediate_act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=10861, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"swinv2-v3-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(\"p1atdev/wd-swinv2-tagger-v3-hf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
